{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Of_Satellite_Images.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wpMfVyJ8RUcH",
        "9-dHtKUGRUfQ",
        "I9m3yWKJa_Wy",
        "q0hojq8tcQ7K",
        "4yfW_oXVchVg",
        "k1Gy75cEcnZZ",
        "Q17Sc1zTcne9",
        "5Y7lPOqKa_ax",
        "xUIjDrd1cnkh",
        "O10DURXPjXVw",
        "VNSdyGoLRUh_",
        "owazrdE_a_dR",
        "SqPCU-w9mEEo",
        "gNoU6Qvlmid5",
        "i0peqCdTnnrK",
        "Cr30oJyWbUDv",
        "FaHe9sqYoaJK",
        "yUapc1aIp2sy",
        "XFdUC9C-qMp0",
        "q9f3u6LdbUJL",
        "OiKxa0LTtYdr",
        "IEI62zRDvFkA",
        "oi-1B5H_RUkW",
        "ZJUF7_L9bUR-",
        "1WCawocT1Pei",
        "Euu1GsRR1P0c",
        "HxY7YH4X1P8D",
        "wSL9NiXc4VMt",
        "cDD9r-pW5Wej",
        "NzzXR60XbUNu",
        "ywB8W8am7lI9",
        "71EUcCjw7lLk",
        "BQEYHRlK_Hww",
        "A-x71Y3x_0-d",
        "iGTMZrm9blvM",
        "PNYa1tFD_Nqj",
        "mFAmXqsPCYr7",
        "yQU-71vMRUnb",
        "OTt59jTlbpq7",
        "5ckHSLy7Ds4n",
        "CyylRW37ELN_",
        "vRXwY4NMGfKk",
        "T3u31OTXIO3N",
        "CEFJJZ0kqctf",
        "0zRQTkJxrm4z",
        "lpbEyGtVbptt",
        "tnTtYFOxs26r",
        "E6tsaiEsuYnd",
        "xC4S3NcSunTv",
        "mn3OEz6MwtPW",
        "JSU2V5MzygTo",
        "nzLfyRd2bpwY",
        "220pAr9izjy9",
        "o2wqXceb0iUO",
        "bjeYqwQl0iXS",
        "N-hsmlYDb5cy",
        "zBhqkkeT2DTT",
        "hnA0OeAG3E8j",
        "5Y2MFP0d3mrV"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPY2DvfIKoeN1tTkEGeee3O"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpMfVyJ8RUcH"
      },
      "source": [
        "# 衛星画像の分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-dHtKUGRUfQ"
      },
      "source": [
        "# [1] テーブルデータの読み込みと探索的分析"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9m3yWKJa_Wy"
      },
      "source": [
        "## 1.テーブルデータを読み込む"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0hojq8tcQ7K"
      },
      "source": [
        "### 1-1.Pandasライブラリをインポートする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU1SU5dZcL2z"
      },
      "source": [
        "**Pandasライブラリをインポート**\n",
        "\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yfW_oXVchVg"
      },
      "source": [
        "### 1-2.CSVファイルを読み込む"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3RpqqVgcnWp"
      },
      "source": [
        "**CSVファイルをインポート**\n",
        "\n",
        "\n",
        "```\n",
        "pd.read_csv('ファイル名')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlbDru3YdD1h"
      },
      "source": [
        "# pandasのインポート\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('train_master.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Gy75cEcnZZ"
      },
      "source": [
        "### 1-3.テーブルデータを表示する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhaWNBCZcncQ"
      },
      "source": [
        "**テーブルデータを表示**\n",
        "\n",
        "\n",
        "```\n",
        "df\n",
        "df.head()\n",
        "df.head(30)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQBNT_4mfbUf"
      },
      "source": [
        "# pandasライブラリをインポートする\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('train_master.csv')\n",
        "\n",
        "# データの先頭15行の表示\n",
        "df.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q17Sc1zTcne9"
      },
      "source": [
        "### 1-4.テーブルデータの概要を把握する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdNenHKpcnh3"
      },
      "source": [
        "**データの要約情報を把握する**\n",
        "\n",
        "\n",
        "```\n",
        "print(df.info())\n",
        "```\n",
        "\n",
        "把握できる内容\n",
        "```\n",
        "データのレコード(行)数、カラム(列)数\n",
        "\n",
        "*   データのレコード(行)数、カラム(列)数\n",
        "*   各カラム(列)に含まれる欠損値の数\n",
        "*   各カラムのデータの型\n",
        "*   データの容量\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o6y9pi5iJwV"
      },
      "source": [
        "# pandasライブラリをインポートする\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('train_master.csv')\n",
        "\n",
        "# データの要約情報を表示する\n",
        "print(df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y7lPOqKa_ax"
      },
      "source": [
        "## 2.正解ラベルの分布を理解する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUIjDrd1cnkh"
      },
      "source": [
        "### 2-1.特定のカラムの値のみを抜き出す"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TWLaFLAcnm_"
      },
      "source": [
        "**DataFrameとSeries**\n",
        "\n",
        "\n",
        "```\n",
        "*   DataFrame... 行と列から成る二次元のデータ\n",
        "*   Series... DataFrameを構成する行もしくは列となる一次元のデータ\n",
        "```\n",
        "**DataFrameから特定のカラム(列)を抜き出す**\n",
        "\n",
        "\n",
        "```\n",
        "データフレーム名['カラム名']\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js0cmziTjTFG"
      },
      "source": [
        "# pandasライブラリをインポートする\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('train_master.csv')\n",
        "\n",
        "# dfのflagカラムのSeriesを変数flagに代入する\n",
        "flag = df['flag']\n",
        "\n",
        "# 出力\n",
        "print(flag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O10DURXPjXVw"
      },
      "source": [
        "### 2-2.カラム内にどのような値がいくつ含まれているのかを調べる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moqIB6yhjbHD"
      },
      "source": [
        "**どのような値が、いくつずつ含まれているのかを調べる**\n",
        "\n",
        "\n",
        "```\n",
        "Series名.value_counts()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvppCUjCj9ut"
      },
      "source": [
        "# pandasライブラリをインポートする\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('train_master.csv')\n",
        "\n",
        "# flagカラム内の値をSeries型として抜き出し、変数flagに代入する\n",
        "flag = df['flag']\n",
        "\n",
        "# flagカラム内のユニークな値とそれらの値の個数を表示する\n",
        "flag.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNSdyGoLRUh_"
      },
      "source": [
        "# [2] 画像データの読み込みと探索的分析"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owazrdE_a_dR"
      },
      "source": [
        "## 1.衛星画像データを読み込む"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqPCU-w9mEEo"
      },
      "source": [
        "### 1-1.skimageからioをインポートする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qf50zb1mEQs"
      },
      "source": [
        "**tiffファイル**\n",
        "\n",
        "\n",
        "```\n",
        "画像を高解像度で保存したい場合などに用いられる\n",
        "```\n",
        "\n",
        "**tiffファイル形式の衛星画像を開く**\n",
        "\n",
        "\n",
        "```\n",
        "from skimage import io\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mP7cyZumgma"
      },
      "source": [
        "# skimageライブラリのioモジュールをインポートする\n",
        "from skimage import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNoU6Qvlmid5"
      },
      "source": [
        "### 1-2.画像を読み込む"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grP1mK23miWM"
      },
      "source": [
        "**tiffファイルを読み込む関数**\n",
        "\n",
        "\n",
        "```\n",
        "io.imread('tiffファイル名')\n",
        "```\n",
        "\n",
        "**ファイルパス(file path)**\n",
        "\n",
        "\n",
        "```\n",
        "*   絶対パス: 最上位の階層から見た目的のファイルの場所\n",
        "*   相対パス: プログラムを実行するファイル内から見た目的のファイルの場所\n",
        "```\n",
        "\n",
        "**相対パスを使用する際**\n",
        "\n",
        "\n",
        "```\n",
        "*   「.」: カレントディレクトリ\n",
        "*   「..」: ひとつ上の階層のディレクトリ\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "# カレントディレクトリ内の、imageディレクトリ内の、train_0.tifファイルを読み込む\n",
        "image = io.imread('./image/train_0.tif')\n",
        "# ひとつ上の階層のディレクトリ内の、train_master.csvファイルを読み込む\n",
        "master = pd.read_csv('../train_master.csv')\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUepZjZLnZxt"
      },
      "source": [
        "# skimageライブラリのioモジュールをインポートする\n",
        "from skimage import io\n",
        "\n",
        "# 画像ファイル'train_0.tif'を読み込む\n",
        "image_dir = './image/'\n",
        "image = io.imread(image_dir + 'train_0.tif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0peqCdTnnrK"
      },
      "source": [
        "### 1-3.画像データの概要を把握する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWAdvvQont65"
      },
      "source": [
        "**データの型を確認**\n",
        "\n",
        "\n",
        "```\n",
        "print(type(確認したいデータ))\n",
        "```\n",
        "\n",
        "**画像データを表すテンソルの形状を確認**\n",
        "\n",
        "\n",
        "```\n",
        "NumPy配列.shape\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIZ2uHwNoTqc"
      },
      "source": [
        "# skimageライブラリのioモジュールをインポートする\n",
        "from skimage import io\n",
        "\n",
        "# 画像ファイル'train_0.tif'を読み込む\n",
        "image_dir = './image/'\n",
        "image = io.imread(image_dir + 'train_0.tif')\n",
        "\n",
        "# 変数imageのデータ型を確認する\n",
        "print(type(image))\n",
        "\n",
        "# 読み込んだ衛星画像の形状(shape)を確認する\n",
        "print(image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr30oJyWbUDv"
      },
      "source": [
        "## 2.衛星画像データの統計量を把握する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaHe9sqYoaJK"
      },
      "source": [
        "### 2-1.画像内に含まれる値の統計量を算出する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_39L83bodDv"
      },
      "source": [
        "**最大値を求める場合**\n",
        "\n",
        "\n",
        "```\n",
        "# 関数\n",
        "np.max(NumPy配列)\n",
        "# メソッド\n",
        "`NumPy配列.max()`\n",
        "```\n",
        "\n",
        "**最小値を求める場合**\n",
        "\n",
        "\n",
        "```\n",
        "# 関数\n",
        "np.min(NumPy配列)\n",
        "# メソッド\n",
        "`NumPy配列.min()`\n",
        "```\n",
        "\n",
        "**平均値を求める場合**\n",
        "\n",
        "\n",
        "```\n",
        "# 関数\n",
        "np.mean(NumPy配列)\n",
        "# メソッド\n",
        "`NumPy配列.mean()`\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmZ8fHKKpDP8"
      },
      "source": [
        "**関数とメソッド**\n",
        "**関数は、それぞれのモジュール内にて独立して定義**\n",
        "\n",
        "\n",
        "```\n",
        "関数名()\n",
        "\n",
        "モジュール名.関数名()\n",
        "```\n",
        "\n",
        "**メソッドはクラス内で定義**\n",
        "\n",
        "\n",
        "```\n",
        "インスタンス名.メソッド名()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oMWe0sapviW"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "# 画像の読み込み\n",
        "image_dir = './image/'\n",
        "image = io.imread(image_dir + 'train_0.tif')\n",
        "\n",
        "# 最大値の算出\n",
        "print('最大値:', np.max(image))\n",
        "\n",
        "# 最小値の算出\n",
        "print('最小値:', np.min(image))\n",
        "\n",
        "# 平均値の算出\n",
        "print('平均値:', np.mean(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUapc1aIp2sy"
      },
      "source": [
        "### 2-2.Matplotlibをインポートする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsvCd8HCp-BL"
      },
      "source": [
        "**グラフや画像の可視化を行う際に便利なライブラリをインポート**\n",
        "\n",
        "\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azIKEkQzqMJx"
      },
      "source": [
        "# Matplotlibのpyplotモジュールをインポートし、pltという省略名をあたえる\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFdUC9C-qMp0"
      },
      "source": [
        "### 2-3.画像30枚分の値をひとつにまとめヒストグラムを作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qraOTaAGqh7y"
      },
      "source": [
        "**ヒストグラムを描画する**\n",
        "\n",
        "\n",
        "```\n",
        "plt.hist(ヒストグラムを表示したい値が入った配列)\n",
        "\n",
        "# ヒストグラム内に表示される棒の数を指定する\n",
        "plt.hist(ヒストグラムを表示したい値が入った配列, bins=表示したい棒の数)\n",
        "```\n",
        "\n",
        "**osライブラリのlistdir()関数で./image/内の画像のファイル名を取得**\n",
        "\n",
        "\n",
        "```\n",
        "# osライブラリのインポート\n",
        "import os\n",
        "\n",
        "# ファイル名のリストを取得\n",
        "image_path_list = os.listdir(ディレクトリ名)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3zSUMZCrTDv"
      },
      "source": [
        "**プログラム説明**\n",
        "\n",
        "\n",
        "```\n",
        "image_path_list = os.listdir(image_dir)\n",
        "\n",
        "image_values = []\n",
        "\n",
        "for image_path in image_path_list:\n",
        "    image = io.imread(image_dir + image_path).flatten()\n",
        "    image_values.extend(image)\n",
        "\n",
        "image_values = np.asarray(image_values)\n",
        "```\n",
        "\n",
        "\n",
        "1.   for文を利用して一枚一枚の画像を読み込み、値をリストに追加\n",
        "2.   NumPy配列として読み込んだ画像は3次元の形状になっているので、flatten()メソッドで１次元に展開\n",
        "3.   Pythonのリスト型データに対して働くextend()メソッドを使用して、リストに値を追加\n",
        "4.   １次元の配列として、変数image_valuesに格納\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olAzZg0TrGZ-"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import os\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ファイル名を取得する\n",
        "image_dir = './image/'\n",
        "image_path_list = os.listdir(image_dir)\n",
        "\n",
        "# ３０枚の画像を読み込み、値をリストにまとめる\n",
        "image_values = []\n",
        "\n",
        "for image_path in image_path_list:\n",
        "    image = io.imread(image_dir + image_path).flatten()\n",
        "    image_values.extend(image)\n",
        "    \n",
        "image_values = np.asarray(image_values)\n",
        "\n",
        "print(np.max(image_values))\n",
        "print(np.min(image_values))\n",
        "print(np.mean(image_values))\n",
        "    \n",
        "# ヒストグラムを描画する\n",
        "plt.hist(image_values, bins=30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9f3u6LdbUJL"
      },
      "source": [
        "## 3.衛星画像を可視化する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiKxa0LTtYdr"
      },
      "source": [
        "### 3-1.チャンネル１の画像を可視化する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULID83hDta80"
      },
      "source": [
        "**１つ目のチャンネルのみを抽出することで、白黒画像として可視化**\n",
        "\n",
        "\n",
        "```\n",
        "plt.imshow(画像, 'gray')\n",
        "```\n",
        "\n",
        "**特定のチャンネルの抽出**\n",
        "**１つ目のチャンネルのみを抽出する**\n",
        "\n",
        "\n",
        "```\n",
        "NumPy配列[:, :, 0]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdbFbFmMvB6b"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 画像の読み込み\n",
        "image = io.imread('image/train_29.tif')\n",
        "\n",
        "# 画像から１つ目のチャンネルのみを抜き出す\n",
        "image_ch1 = image[:, :, 0]\n",
        "\n",
        "# 画像を可視化する\n",
        "plt.imshow(image_ch1, 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEI62zRDvFkA"
      },
      "source": [
        "### 3-2.７つのチャンネルをそれぞれ抽出し並べて可視化する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0gsYrMyvFhc"
      },
      "source": [
        "**Matplotlibライブラリで複数の図を並べて表示する方法**\n",
        "\n",
        "\n",
        "```\n",
        "fig, axes = plt.subplots(nrows=行数, ncols=列数)\n",
        "```\n",
        "\n",
        "**fig、axesという変数に代入されたオブジェクト**\n",
        "\n",
        "\n",
        "```\n",
        "*   fig: 全てのaxesを包摂(含む)するもの\n",
        "*   axes: 一つ一つの図(画像)を表示するスペース\n",
        "```\n",
        "\n",
        "**一つ一つの画像を表示する**\n",
        "\n",
        "\n",
        "```\n",
        "# 複数の画像を表示するための準備\n",
        "fig, axes = plt.subplots(nrows=行数, ncols=列数)\n",
        "\n",
        "# １枚目に表示する画像の指定\n",
        "axes[0].imshow('画像ファイル名')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN04R-xvwOJn"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 画像の読み込み\n",
        "image = io.imread('./image/train_29.tif')\n",
        "\n",
        "# 画像を複数描画するための行数、列数の指定\n",
        "fig, axes = plt.subplots(1, 7, figsize=(14, 4))\n",
        "\n",
        "# 各axesに画像を描画する\n",
        "for i in range(7):\n",
        "    axes[i].imshow(image[:, :, i], 'gray')\n",
        "    axes[i].set_title('Band_'+str(i+1))\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi-1B5H_RUkW"
      },
      "source": [
        "# [3] 前処理とデータセット作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJUF7_L9bUR-"
      },
      "source": [
        "## 1.画像データの前処理を設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WCawocT1Pei"
      },
      "source": [
        "### 1-1.正規化の方針を定める"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7HU2a4F1Psc"
      },
      "source": [
        "**正規化の処理として、今回は5000〜30000の範囲に収まっていない値は外れ値として扱う**\n",
        "\n",
        "\n",
        "```\n",
        "1.   全ての値を、５０００〜３００００の範囲内に収める。\n",
        "2.   全ての値を、0〜1の間に正規化する。\n",
        "```\n",
        "\n",
        "**全ての値を、５０００〜３００００の範囲内に収める**\n",
        "\n",
        "\n",
        "```\n",
        "np.clip(元の値, 最小値, 最大値)\n",
        "```\n",
        "**全ての値を、0〜1の間に正規化する**\n",
        "\n",
        "\n",
        "```\n",
        "(x - 最小値) / (最大値 - 最小値)\n",
        "\n",
        "#今回の場合\n",
        "(x - 5000) / (30000 - 5000)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9erKHJu2NX9"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "\n",
        "# 画像の読み込み\n",
        "image = io.imread('./image/train_0.tif')\n",
        "\n",
        "# 関数の定義\n",
        "def normalize(image):\n",
        "    max = 30000\n",
        "    min = 5000\n",
        "    \n",
        "    # np.clip()関数の適用\n",
        "    image_normalized = np.clip(image, min, max)\n",
        "    \n",
        "    # 正規化の設定\n",
        "    image_normalized = (image_normalized - min) / (max - min)\n",
        "    return image_normalized\n",
        "\n",
        "# 関数の実行\n",
        "image_normalized = normalize(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euu1GsRR1P0c"
      },
      "source": [
        "### 1-2.学習データと検証データに分割する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7BhSexE2Wmi"
      },
      "source": [
        "**各カラムの値が含まれた配列を抽出する**\n",
        "\n",
        "\n",
        "```\n",
        "Series型のデータ.values\n",
        "```\n",
        "\n",
        "**学習データと検証データに分割する**\n",
        "\n",
        "\n",
        "```\n",
        "x_train, x_val, y_train, y_val = train_test_split(入力画像, 正解ラベル, test_size=検証データの割合, stratify=正解ラベル, random_state=数字)\n",
        "```\n",
        "\n",
        "**train_test_split()関数内に含まれる引数**\n",
        "\n",
        "\n",
        "```\n",
        "1.   test_size : 浮動小数点数を指定した場合 -> 検証データの割合(test_size=0.2とした場合、80％が学習データ、20％が検証データとなるようにデータが分割される。)\n",
        "整数を指定した場合 -> 検証データの絶対数(test_size=500とした場合、検証データの数が500となるようにデータが分割される。)\n",
        "2.   stratify : 正解ラベルを代入する。正解ラベルの各クラスの比率を保ったままデータの分割を行いたい際に設定する。\n",
        "3.   random_state : 乱数seedとして使用する数字。同じ分割方法を再現するために設定される。\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBoteWQ03t4t"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "master = pd.read_csv('train_master.csv')\n",
        "\n",
        "# 入力データの定義\n",
        "image_file_list = master['file_name'].values\n",
        "# 正解ラベルの定義\n",
        "image_label_list = master['flag'].values\n",
        "\n",
        "# 学習データ、検証データにラベルの偏りが無いように分割する。\n",
        "x_train, x_val, y_train, y_val = train_test_split(image_file_list, image_label_list, test_size=0.5, stratify=image_label_list, random_state=42)\n",
        "\n",
        "print('学習データの数', len(x_train))\n",
        "print('検証データの数', len(y_val))\n",
        "print('---------------------------------------------')\n",
        "print('学習データに含まれる各正解ラベルの数')\n",
        "print(np.unique(y_train, return_counts=True))\n",
        "print('---------------------------------------------')\n",
        "print('検証データに含まれる各正解ラベルの数')\n",
        "print(np.unique(y_val, return_counts=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxY7YH4X1P8D"
      },
      "source": [
        "### 1-3.transforms.Compose()を使いこなす"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyPucLkK1QCl"
      },
      "source": [
        "**transforms.Compose()クラスのインスタンス化**\n",
        "\n",
        "\n",
        "```\n",
        "transform = transforms.Compose([\n",
        "    前処理クラス1,\n",
        "    前処理クラス2,\n",
        "    前処理クラス3\n",
        "])\n",
        "前処理後の画像 = transform(元の画像)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97hlnQHB4TXP"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from skimage import io\n",
        "from torchvision import transforms\n",
        "\n",
        "# 画像の読み込み\n",
        "image = io.imread('./image/train_0.tif')\n",
        "\n",
        "# transforms.Compose()クラスのインスタンス生成\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 前処理の実行\n",
        "image_transformed = transform(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSL9NiXc4VMt"
      },
      "source": [
        "### 1-4.正規化を行う前処理クラスを作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH9u7E6f4Zve"
      },
      "source": [
        "**画像データを正規化する前処理関数**\n",
        "\n",
        "\n",
        "```\n",
        "def normalize(image):\n",
        "    max = 30000\n",
        "    min = 5000\n",
        "    image_normalized = np.clip(image, min, max)\n",
        "    image_normalized = (image_normalized - min) / (max - min)\n",
        "    return image_normalized\n",
        "```\n",
        "\n",
        "**上記と全く同じ処理を、transforms.Compose()クラスに含めて実行できるように設定する**\n",
        "\n",
        "\n",
        "```\n",
        "class Normalize():\n",
        "    def __call__(self, image):\n",
        "        max = 30000\n",
        "        min = 5000\n",
        "        image_normalized = np.clip(image, min, max)\n",
        "        image_normalized = (image_normalized - min) / (max - min)\n",
        "        return image_normalized\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCUKulxZ5PVq"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from torchvision import transforms\n",
        "\n",
        "# 画像の読み込み\n",
        "image = io.imread('./image/train_0.tif')\n",
        "\n",
        "# 正規化クラスの設定\n",
        "class Normalize():\n",
        "    def __call__(self, image):\n",
        "        max = 30000\n",
        "        min = 5000\n",
        "        image_normalized = np.clip(image, min, max)\n",
        "        image_normalized = (image_normalized - min) / (max - min)\n",
        "        return image_normalized\n",
        "\n",
        "# Normalize()クラスを含めて、transforms.Compose()のインスタンスを作成する\n",
        "transform = transforms.Compose([\n",
        "    Normalize(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "image_transformed = transform(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDD9r-pW5Wej"
      },
      "source": [
        "### 1-5.学習時と検証時で異なる前処理を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOA_YhUp6tFv"
      },
      "source": [
        "**あらかじめ学習時と検証時で前処理の動作を分割**\n",
        "\n",
        "\n",
        "```\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        Normalize(),\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        Normalize(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "}\n",
        "```\n",
        "\n",
        "**transformの実行方法**\n",
        "\n",
        "\n",
        "```\n",
        "# 学習時用の前処理\n",
        "transform['train'](image)\n",
        "\n",
        "# 検証時用の前処理\n",
        "transform['val'](image)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK45Skun7gpb"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from torchvision import transforms\n",
        "\n",
        "image = io.imread('./image/train_0.tif')\n",
        "\n",
        "# 正規化クラスの設定\n",
        "class Normalize():\n",
        "    def __call__(self, image):\n",
        "        max = 30000\n",
        "        min = 5000\n",
        "        image_normalized = np.clip(image, min, max)\n",
        "        image_normalized = (image_normalized - min) / (max - min)\n",
        "        return image_normalized\n",
        "\n",
        "# 学習時の前処理を'train'キー(key)に、検証時の前処理を'val'キー(key)に設定しましょう。\n",
        "transform = {\n",
        "    # 学習時に実行する前処理\n",
        "    'train': transforms.Compose([\n",
        "        Normalize(),\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "    # 検証時に実行する前処理\n",
        "    'val': transforms.Compose([\n",
        "        Normalize(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "}\n",
        "\n",
        "# 学習時(train)に行う前処理を実行する\n",
        "image_transformed = transform['train'](image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzzXR60XbUNu"
      },
      "source": [
        "## 2.Datasetを設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywB8W8am7lI9"
      },
      "source": [
        "### 2-1.Datasetクラスとは"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vESUBnHb7ppR"
      },
      "source": [
        "**Datasetクラスの役割**\n",
        "\n",
        "\n",
        "```\n",
        "*   入力画像及び正解ラベルの読み込み\n",
        "*   データの前処理\n",
        "```\n",
        "\n",
        "\n",
        "**衛星(Satellite)画像用のデータセット**\n",
        "\n",
        "\n",
        "```\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SatelliteDataset(Dataset):\n",
        "    def __init__(self, image_name_list, label_list, phase=None):\n",
        "        self.image_name_list = image_name_list\n",
        "        self.label_list = label_list\n",
        "        self.phase = phase\n",
        "\n",
        "    def __len__(self, ):\n",
        "        return len(self.image_name_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # index番目の画像を読み込み、前処理を行う\n",
        "        image_name = self.image_name_list[index]\n",
        "        image = io.imread(image_dir + image_name)\n",
        "        image = transform[self.phase](image)\n",
        "\n",
        "        # index番目のラベルを取得する\n",
        "        label = self.label_list[index]\n",
        "\n",
        "        return image, label\n",
        "```\n",
        "\n",
        "**Datasetクラスの実装**\n",
        "\n",
        "\n",
        "```\n",
        "1.   __init__\n",
        "-> 初期化を行う。\n",
        "2.   __len__\n",
        "-> １エポックあたりに使用するデータ数を返す。\n",
        "3.   __getitem__\n",
        "-> データの読み込み、前処理を行った上で、入力画像と正解ラベルのセットを返す。\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71EUcCjw7lLk"
      },
      "source": [
        "### 2-2.`__init__`を実装する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkDrbvHb-gFu"
      },
      "source": [
        "**学習用と検証用の２種類のDatasetインスタンスを生成することを想定し、SatelliteDatasetクラスを作成*\n",
        "\n",
        "```\n",
        "*   phase: 学習用or検証用の指定\n",
        "*   image_name_list: 使用する画像データの指定(学習用x_trainもしくは検証用x_val)\n",
        "*   label_list: 使用する正解ラベルの指定(学習用y_trainもしくは検証用y_val)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6FOXUmb_EKs"
      },
      "source": [
        "# データの読み込み\n",
        "image_dir = './image/'\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "master = pd.read_csv('train_master.csv')\n",
        "\n",
        "image_name_list = master['file_name'].values\n",
        "label_list = master['flag'].values\n",
        "\n",
        "# 学習用、検証用の分割\n",
        "x_train, x_val, y_train, y_val = train_test_split(image_name_list, label_list, test_size=0.5, stratify=label_list, random_state=42)\n",
        "\n",
        "# SatelliteDatasetクラスの設定\n",
        "class SatelliteDataset(Dataset):\n",
        "    # __init__の設定\n",
        "    def __init__(self, image_name_list, label_list, phase):\n",
        "        self.image_name_list = image_name_list\n",
        "        self.label_list = label_list\n",
        "        self.phase = phase\n",
        "\n",
        "# 空欄に'train'or'val'の値を代入し、正しくインスタンスを作成してください\n",
        "train_dataset = SatelliteDataset(x_train, y_train, phase='train')\n",
        "val_dataset = SatelliteDataset(x_val, y_val, phase='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a25rdkr9_HgI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQEYHRlK_Hww"
      },
      "source": [
        "### 2-3.`__len__`を実装する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twSaJK7I_Nnb"
      },
      "source": [
        "**１エポックあたりに全データを一度ずつ読み込む**\n",
        "\n",
        "\n",
        "```\n",
        "def __len__(self):\n",
        "    return len(入力データ)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2gkC6fo_0PR"
      },
      "source": [
        "# データの読み込み\n",
        "image_dir = './image/'\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "master = pd.read_csv('train_master.csv')\n",
        "\n",
        "image_name_list = master['file_name'].values\n",
        "label_list = master['flag'].values\n",
        "\n",
        "# 学習用、検証用の分割\n",
        "x_train, x_val, y_train, y_val = train_test_split(image_name_list, label_list, test_size=0.5, stratify=label_list, random_state=42)\n",
        "\n",
        "class SatelliteDataset(Dataset):\n",
        "    def __init__(self, image_name_list, label_list, phase):\n",
        "        self.image_name_list = image_name_list\n",
        "        self.label_list = label_list\n",
        "        self.phase = phase\n",
        "        \n",
        "    def __len__(self, ):\n",
        "        # １エポックあたりに読み込むデータ数として、入力データの数を指定しましょう。\n",
        "        return len(self.image_name_list)\n",
        "        \n",
        "train_dataset = SatelliteDataset(x_train, y_train, phase='train')\n",
        "val_dataset = SatelliteDataset(x_val, y_val, phase='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-x71Y3x_0-d"
      },
      "source": [
        "### 2-4.`__getitem__`を設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yi5UI-T_8A_"
      },
      "source": [
        "**SatelliteDataset内の__getitem__()関数の設定**\n",
        "\n",
        "\n",
        "```\n",
        "image_dir = './image/'\n",
        "\n",
        "def __getitem__(self, インデックス):\n",
        "\n",
        "    # インデックス番目の入力画像を読み込み、前処理を行う\n",
        "    入力画像のファイル名 = self.入力画像のファイル名リスト[インデックス]\n",
        "    画像の配列 = io.imread(image_dir + 入力画像のファイル名)\n",
        "    前処理後の入力画像 = transform[学習or検証](画像の配列)\n",
        "\n",
        "    # インデックス番目の正解ラベルを取得する\n",
        "    正解ラベル = self.正解ラベルのリスト[インデックス]\n",
        "\n",
        "    # 読み込んだ入力画像、正解ラベルを返り値とする\n",
        "    return 前処理後の入力画像, 正解ラベル\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U5FruknAi01"
      },
      "source": [
        "# データの読み込み\n",
        "image_dir = './image/'\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "master = pd.read_csv('train_master.csv')\n",
        "\n",
        "image_name_list = master['file_name'].values\n",
        "label_list = master['flag'].values\n",
        "\n",
        "# 学習用、検証用の分割\n",
        "x_train, x_val, y_train, y_val = train_test_split(image_name_list, label_list, test_size=0.5, stratify=label_list, random_state=42)\n",
        "\n",
        "class SatelliteDataset(Dataset):\n",
        "    def __init__(self, image_name_list, label_list, phase):\n",
        "        self.image_name_list = image_name_list\n",
        "        self.label_list = label_list\n",
        "        self.phase = phase\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self, ):\n",
        "        # １エポックあたりに読み込むデータ数として、入力データの数を指定しましょう。\n",
        "        return len(self.image_name_list)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # index番目の画像を読み込み、前処理を行う\n",
        "        image_name = self.image_name_list[index]\n",
        "        image = io.imread(image_dir + image_name)\n",
        "        image = transform[self.phase](image)\n",
        "\n",
        "        # index番目のラベルを取得する\n",
        "        label = self.label_list[index]\n",
        "        \n",
        "        return image, label\n",
        "        \n",
        "train_dataset = SatelliteDataset(x_train, y_train, phase='train')\n",
        "val_dataset = SatelliteDataset(x_val, y_val, phase='val')\n",
        "\n",
        "print(val_dataset.__getitem__(0)[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGTMZrm9blvM"
      },
      "source": [
        "## 3.DataLoaderを設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNYa1tFD_Nqj"
      },
      "source": [
        "### 3-1.DataLoaderのインスタンスを作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntWiqaApBJxC"
      },
      "source": [
        "**DataLoadeのインスタンス生成の際に必要な引数を設定**\n",
        "\n",
        "\n",
        "```\n",
        "*   dataset : 使用するデータセットの指定\n",
        "*   batch_size : バッチサイズの指定\n",
        "*   shuffle : データをロードする順番のシャッフルの有無の指定\n",
        "```\n",
        "\n",
        "**DataLoaderをインポート**\n",
        "\n",
        "\n",
        "```\n",
        "from torch.utils.data import DataLoader\n",
        "```\n",
        "\n",
        "**学習用、検証用DataLoaderの引数**\n",
        "\n",
        "\n",
        "```\n",
        "*   学習用データローダー(train_dataloader)\n",
        "dataset : 学習用のデータセット(train_dataset)\n",
        "batch_size : 64\n",
        "shuffle : あり(True)\n",
        "*   検証用データローダー(val_dataloader)\n",
        "dataset : 検証用のデータセット(val_dataset)\n",
        "batch_size : 64\n",
        "shuffle : なし(False)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDUmLu1NCU2-"
      },
      "source": [
        "# Datasetのインスタンス作成\n",
        "train_dataset = SatelliteDataset(x_train, y_train, phase='train')\n",
        "val_dataset = SatelliteDataset(x_val, y_val, phase='val')\n",
        "\n",
        "# ライブラリのインポート\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# DataLoaderのインスタンス作成\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFAmXqsPCYr7"
      },
      "source": [
        "### 3-2.ataLoaderインスタンスを辞書に格納する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxgWl9wmCfEe"
      },
      "source": [
        "**dataloaders_dictという変数に、以下のような対応関係で辞書を設定**\n",
        "\n",
        "\n",
        "```\n",
        "キー(key)\t値(value)\n",
        "'train'\ttrain_dataloader\n",
        "'val'\tval_dataloader\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juUIolvUCvPr"
      },
      "source": [
        "# データセットの作成\n",
        "train_dataset = SatelliteDataset(x_train, y_train, phase='train')\n",
        "val_dataset = SatelliteDataset(x_val, y_val, phase='val')\n",
        "\n",
        "# データローダーの作成\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# データローダーを辞書として格納する\n",
        "dataloaders_dict = {\n",
        "    'train' : train_dataloader,\n",
        "    'val' : val_dataloader\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQU-71vMRUnb"
      },
      "source": [
        "# [4] モデリング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTt59jTlbpq7"
      },
      "source": [
        "## 1.画像分類モデルを構築する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ckHSLy7Ds4n"
      },
      "source": [
        "### 1-1.モデリングの方針を考える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD6vpyrODs7k"
      },
      "source": [
        "**画像分類モデルを構築する際の2つの選択肢**\n",
        "\n",
        "\n",
        "```\n",
        "1.   モデルを自分で構築する\n",
        "2.   すでに存在する高性能なモデルを読みこみ調整を加える\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyylRW37ELN_"
      },
      "source": [
        "### 1-2.画像分類モデルを選定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj8UHXVIESXk"
      },
      "source": [
        "**PreResnetというモデルの選択理由**\n",
        "\n",
        "\n",
        "```\n",
        "1.   CIFAR-100という、画像の(高さ、幅)が当クエストの衛星データと同じく(32, 32)のデータセットにて高い分類精度を果たしているモデルであること\n",
        "2.   層の深さを変更することで、計算コストと予測精度のトレードオフを容易に調整できること\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDVzS9OAEsiR"
      },
      "source": [
        "**モデルを構築する際はpreresnet.preresnet()関数を実行**\n",
        "\n",
        "\n",
        "```\n",
        "# モジュールのインポート\n",
        "import preresnet\n",
        "# モデルの構築\n",
        "net = preresnet.preresnet()\n",
        "```\n",
        "\n",
        "**PreResnetの層の深さを20に指定**\n",
        "\n",
        "\n",
        "```\n",
        "# 層の深さを20に指定する\n",
        "net = preresnet.preresnet(depth=20)\n",
        "```\n",
        "\n",
        "**一般的な画像分類モデル**\n",
        "\n",
        "\n",
        "```\n",
        "1.   畳み込み層: 画像の特徴量を抽出する。\n",
        "2.   全結合層: 畳み込み層によって得られた特徴量を元に、クラスの分類を行う。\n",
        "```\n",
        "\n",
        "**転移学習 (学習済みパラメータの転用)**\n",
        "\n",
        "\n",
        "```\n",
        "*   1の畳み込み層による特徴量の抽出は、膨大なデータセットによる学習済みのパラメータを使用し\n",
        "*   2の全結合層(特に出力層)によるクラスの分類のみ、手元にあるデータセットで新たにパラメータの学習を行う\n",
        "```\n",
        "\n",
        "**今回転移学習を採用しない理由**\n",
        "\n",
        "\n",
        "```\n",
        "*   十分な量の学習データが存在する\n",
        "*   入力画像が７チャンネルの衛星画像である\n",
        "*   ゴルフ場が含まれているか否かの二値分類問題である\n",
        "*   一般的なデータセットとかけ離れた特徴を持っている\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eXTxl4pGcR5"
      },
      "source": [
        "# preresnetモジュールの読み込み\n",
        "import preresnet\n",
        "\n",
        "# 層の深さを２０に指定してクラスPreResnetのインスタンス作成\n",
        "net = preresnet.preresnet(depth=20)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRXwY4NMGfKk"
      },
      "source": [
        "### 1-3.モデルのどこに修正を加えるべきかを見極める"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKvJh1CTGpUr"
      },
      "source": [
        "**注意する点**\n",
        "\n",
        "\n",
        "```\n",
        "*   読み込んだモデルが元々学習対象としていたタスク\n",
        "*   今回自分が取り組むべきタスク\n",
        "```\n",
        "\n",
        "**タスクが画像分類問題である場合**\n",
        "\n",
        "\n",
        "```\n",
        "1.   入力する画像データの(高さ、幅)が大きく違っていないか\n",
        "2.   入力する画像データの(チャンネル数)に違いはないか\n",
        "3.   分類するカテゴリ数に違いはないか\n",
        "```\n",
        "\n",
        "**1. 入力する画像データの(高さ、幅)に大きな違いはないか**\n",
        "\n",
        "\n",
        "```\n",
        "今回は問題なし\n",
        "```\n",
        "\n",
        "**2. 入力する画像データの(チャンネル数)に違いはないか**\n",
        "\n",
        "\n",
        "```\n",
        "CIFAR-100データセットの画像データは、RGBカラー画像なので、問題あり\n",
        "```\n",
        "\n",
        "**考えられる2つの対策**\n",
        "\n",
        "\n",
        "```\n",
        "A. データに変更を加える方法: 画像データからRGBのチャンネルのみを抜き出し、７チャンネル->３チャンネルに変更する。\n",
        "B. モデルに変更を加える方法: モデルが入力データとして受け入れるチャンネル数を、3チャンネル->7チャンネルに変更する。\n",
        "```\n",
        "\n",
        "**3. 分類するカテゴリ数に違いはないか**\n",
        "\n",
        "\n",
        "```\n",
        "二値分類タスクであるため、この点に関しても、問題あり\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3u31OTXIO3N"
      },
      "source": [
        "### 1-4.モデルの入力層に修正を加える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN2TQud6ITJl"
      },
      "source": [
        "**モデルの構造を確認**\n",
        "\n",
        "\n",
        "```\n",
        "import preresnet\n",
        "\n",
        "net = preresnet.preresnet(depth=20)\n",
        "print(net)\n",
        "```\n",
        "\n",
        "\n",
        "**出力した値の先頭部分を抜粋したもの**\n",
        "\n",
        "\n",
        "```\n",
        "PreResNet(\n",
        "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "  (layer1): Sequential(\n",
        "    (0): BasicBlock(\n",
        "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "    )\n",
        "```\n",
        "\n",
        "**今回注目すべき部分**\n",
        "\n",
        "\n",
        "```\n",
        "(conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "*   1つ目の引数3はこの層が入力として受け取るチャンネル数\n",
        "*   2つ目の引数16は、この層が出力として、吐き出すチャンネル数\n",
        "```\n",
        "\n",
        "**すでに構築されたモデル内の特定の層に変更を加える場合**\n",
        "\n",
        "\n",
        "```\n",
        "モデルの変数名.層の名前 = 層の再定義\n",
        "\n",
        "# 今回の場合\n",
        "*   モデル名: net\n",
        "*   層の名前: conv1\n",
        "*   再定義したい層: Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98uoMldYqX1m"
      },
      "source": [
        "# モデルが定義されたモジュールのインポート\n",
        "import preresnet\n",
        "\n",
        "# torch.nnをnnとしてインポートする\n",
        "import torch.nn as nn\n",
        "\n",
        "# モデルの読み込み\n",
        "net = preresnet.preresnet(depth=20)\n",
        "\n",
        "# モデルの入力層の再定義\n",
        "net.conv1 = nn.Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEFJJZ0kqctf"
      },
      "source": [
        "### 1-5.モデルの出力層に修正を加える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aGWh63OqiCA"
      },
      "source": [
        "**今回の問題点**\n",
        "\n",
        "\n",
        "```\n",
        "*   入力チャンネル数の違い\n",
        "*   分類カテゴリ数の違い\n",
        "```\n",
        "\n",
        "**分類カテゴリ数の違いを出力層に調整を加えることで解決**\n",
        "**読み込んだモデルPreResnetの最後尾部分を確認**\n",
        "\n",
        "\n",
        "```\n",
        "(bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  (relu): ReLU(inplace=True)\n",
        "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
        "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "**引数out_featuresに代入された整数が出力する値の数を100から2へ変更**\n",
        "\n",
        "\n",
        "```\n",
        "# モデルの出力層の再定義\n",
        "net.fc = nn.Linear(in_features=64, out_features=2, bias=True)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5haXXFjHrVYx"
      },
      "source": [
        "# モデルが定義されたモジュールのインポート\n",
        "import preresnet\n",
        "\n",
        "# torch.nnをnnとしてインポートする\n",
        "import torch.nn as nn\n",
        "\n",
        "# モデルの読み込み\n",
        "net = preresnet.preresnet(depth=20)\n",
        "\n",
        "# モデルの入力層の再定義\n",
        "net.conv1 = nn.Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "# モデルの出力層の再定義\n",
        "net.fc = nn.Linear(in_features=64, out_features=2, bias=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zRQTkJxrm4z"
      },
      "source": [
        "### 1-6.損失関数と最適化手法を設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0lsyZYvrvpQ"
      },
      "source": [
        "**損失関数を設定**\n",
        "\n",
        "\n",
        "```\n",
        "from torch import nn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "```\n",
        "\n",
        "**最適化手法の例**\n",
        "\n",
        "\n",
        "```\n",
        "*   SGD\n",
        "*   RMSprop\n",
        "*   Adadelta\n",
        "*   Adam\n",
        "```\n",
        "\n",
        "\n",
        "**Adamの実装**\n",
        "\n",
        "\n",
        "```\n",
        "from torch import optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "```\n",
        "\n",
        "**Adamのその他の引数**\n",
        "\n",
        "\n",
        "```\n",
        "*   lr: 学習率\n",
        "*   weight_decay: 重みの減衰率\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BhmDGYvsvNN"
      },
      "source": [
        "# モデルが定義されたモジュールのインポート\n",
        "import preresnet\n",
        "\n",
        "# torch.nnをnnとしてインポートする\n",
        "from torch import nn, optim\n",
        "import torch\n",
        "\n",
        "# モデルの読み込み\n",
        "net = preresnet.preresnet(depth=20)\n",
        "\n",
        "# モデルの入力層の再定義\n",
        "net.conv1 = nn.Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "# モデルの出力層の再定義\n",
        "net.fc = nn.Linear(in_features=64, out_features=2, bias=True)\n",
        "\n",
        "# 損失関数の設定\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の設定 net.parameters()を更新するパラメータとして設定する\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "# 確認\n",
        "print(loss_fn)\n",
        "print(optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpbEyGtVbptt"
      },
      "source": [
        "## 2.学習を行う関数を作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnTtYFOxs26r"
      },
      "source": [
        "### 2-1.関数実行直後に行う処理を設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f54KIyIYs23x"
      },
      "source": [
        "**train_model()関数が受け取る引数を設定**\n",
        "**train_model()関数の引数**\n",
        "\n",
        "\n",
        "```\n",
        "*   net : モデルの指定\n",
        "*   epochs : エポック数の指定\n",
        "*   loss_fn : 損失関数の指定\n",
        "*   optimizer : 最適化手法の指定\n",
        "```\n",
        "\n",
        "**使用する機器(CPU or GPU)の設定**\n",
        "\n",
        "\n",
        "```\n",
        "*   GPUが使用できる場合はGPUを使う\n",
        "*   GPUが使用できない場合にはCPUを使う\n",
        "\n",
        "# 学習に使用する機器(device)の設定\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "```\n",
        "\n",
        "**上記のコードの省略前**\n",
        "\n",
        "\n",
        "```\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "```\n",
        "\n",
        "**device間のデータの移動**\n",
        "**モデルをGPUに移動させたい場合**\n",
        "\n",
        "\n",
        "```\n",
        "net.to('cuda')\n",
        "```\n",
        "\n",
        "**評価指標IoU(Intersection over Union)の初期値の設定**\n",
        "\n",
        "\n",
        "```\n",
        "# ベストスコアの初期値\n",
        "best_iou = 0.0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NYnmaZEvEzf"
      },
      "source": [
        "# 学習を行う関数train_modelの定義\n",
        "def train_model(net, epochs, loss_fn, optimizer):\n",
        "    \n",
        "    # 学習に使用する機器(device)の設定\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # モデルを設定した機器(device)に移動する\n",
        "    net.to(device)\n",
        "    \n",
        "    # ベストスコアの初期値\n",
        "    best_iou = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6tsaiEsuYnd"
      },
      "source": [
        "### 2-2.各エポックごとに行う処理を設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfTUai-YuYsJ"
      },
      "source": [
        "**エポックごとに行う処理**\n",
        "\n",
        "```\n",
        "for epoch in range(epochs):\n",
        "```\n",
        "\n",
        "**現在のエポック数の確認**\n",
        "\n",
        "\n",
        "```\n",
        "# 現在のエポック数の出力\n",
        "print(f'Epoch: {epoch+1} / {epochs}')\n",
        "print('--------------------------')\n",
        "```\n",
        "\n",
        "**学習、検証のループ**\n",
        "\n",
        "\n",
        "```\n",
        "# 毎エポック: 学習、検証を別々に行う　phaseで学習or検証を参照\n",
        "for phase in ['train', 'val']:\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tooClLlyvAqp"
      },
      "source": [
        "def train_model(net, epochs, loss_fn, optimizer):\n",
        "    \n",
        "    # 学習に使用する機器(device)の設定\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # モデルを設定した機器(device)に移動する\n",
        "    net.to(device)\n",
        "    \n",
        "    # ベストスコアの初期値\n",
        "    best_iou = 0.0\n",
        "    \n",
        "    # エポックループの設定\n",
        "    for epoch in range(epochs):\n",
        "    \n",
        "        # 現在のエポック数の出力\n",
        "        print(f'Epoch: {epoch+1} / {epochs}')\n",
        "        print('--------------------------')\n",
        "\n",
        "        # 毎エポック: 学習・検証ループの設定\n",
        "        for phase in ['train', 'val']:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC4S3NcSunTv"
      },
      "source": [
        "### 2-3.毎エポックの学習時、検証時に行う処理を設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGiGtmPbvQCr"
      },
      "source": [
        "**学習モード、検証モードの切り替え**\n",
        "\n",
        "\n",
        "```\n",
        "*   モデル.train() : モデルを学習モードに切り替え\n",
        "*   モデル.eval() : モデルを検証モードに切り替え\n",
        "\n",
        "if phase == 'train':\n",
        "    net.train()\n",
        "else:\n",
        "    net.eval()\n",
        "```\n",
        "\n",
        "**学習モードと検証モードでは、モデルが実行する処理が異なる部分**\n",
        "\n",
        "\n",
        "```\n",
        "*   検証モード時には、Dropout層による処理が実行されない\n",
        "```\n",
        "\n",
        "**評価指標のリセット**\n",
        "\n",
        "\n",
        "```\n",
        "# 損失値のリセット\n",
        "epoch_loss = 0.0\n",
        "\n",
        "# 予測値リストのリセット\n",
        "pred_list = []\n",
        "\n",
        "# 正解値リストのリセット\n",
        "true_list = []\n",
        "```\n",
        "\n",
        "**ミニバッチごとのループ**\n",
        "\n",
        "\n",
        "```\n",
        "for images, labels in dataloaders_dict[phase]:\n",
        "```\n",
        "\n",
        "**評価指標を正解率ではなく、IoUとする理由**\n",
        "\n",
        "\n",
        "```\n",
        "正解率を評価指標とすると、無条件で、データ数の多いラベルを予測値とするといった、単純な予測が高い評価を獲得することになってしまうため\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5ldgOe4wiMo"
      },
      "source": [
        "def train_model(net, epochs, loss_fn, optimizer):\n",
        "    \n",
        "    # 学習に使用する機器(device)の設定\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # モデルを設定した機器(device)に移動する\n",
        "    net.to(device)\n",
        "    \n",
        "    # ベストスコアの初期値\n",
        "    best_iou = 0.0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "    \n",
        "        # 現在のエポック数の出力\n",
        "        print(f'Epoch: {epoch+1} / {epochs}')\n",
        "        print('--------------------------')\n",
        "\n",
        "        # 毎エポック: 学習、検証を別々に行う　phaseで学習or検証を参照\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            # 学習モード、検証モードの切替\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "            else:\n",
        "                net.eval()         \n",
        "                \n",
        "            # 損失値のリセット\n",
        "            epoch_loss = 0.0\n",
        "            # 予測値リストのリセット\n",
        "            pred_list = []\n",
        "            # 正解値リストのリセット\n",
        "            true_list = []\n",
        "                      \n",
        "            # dataloaderから、ミニバッチ(batch_size)単位でのデータの読み込み\n",
        "            for images, labels in dataloaders_dict[phase]:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn3OEz6MwtPW"
      },
      "source": [
        "### 2-4.ミニバッチごとに行う処理を設定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85eOGX-wtTQ"
      },
      "source": [
        "**データをモデルと同じdeviceへ移動させる**\n",
        "\n",
        "\n",
        "```\n",
        "# 入力データ、正解ラベルをモデルと同じdeviceへ移動\n",
        "images = images.float().to(device)\n",
        "labels = labels.to(device)\n",
        "```\n",
        "\n",
        "**勾配情報のリセット**\n",
        "\n",
        "\n",
        "```\n",
        "# 勾配情報の初期化\n",
        "optimizer.zero_grad()\n",
        "```\n",
        "\n",
        "**モデルによる入力データの変換と、パラメータの更新**\n",
        "\n",
        "\n",
        "```\n",
        "with torch.set_grad_enabled(phase=='train'):\n",
        "\n",
        "    # モデルによる計算\n",
        "    outputs = net(images)\n",
        "    # 損失値の計算\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    # 予測ラベルの算出\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    # 学習時のみ、バックプロパゲーションとパラメータ更新\n",
        "    if phase == 'train':\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "```\n",
        "\n",
        "**ミニバッチごとに算出した情報を追加していく処理を設定**\n",
        "\n",
        "\n",
        "```\n",
        "1.   epoch_lossに当ミニバッチ分の損失を追加する\n",
        "2.   当ミニバッチ分の予測ラベルをpred_listに追加する\n",
        "3.   当ミニバッチ分の正解ラベルをtrue_listに追加する\n",
        "```\n",
        "\n",
        "**上記の処理の記述**\n",
        "\n",
        "\n",
        "```\n",
        "# 損失値の追加\n",
        "epoch_loss += loss.item() * images.size(0)\n",
        "\n",
        "# 予測ラベルの追加\n",
        "preds = preds.to('cpu').numpy()\n",
        "pred_list.extend(preds)\n",
        "\n",
        "# 正解ラベルの追加\n",
        "labels = labels.to('cpu').numpy()\n",
        "true_list.extend(labels)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK6IaIXYyVXx"
      },
      "source": [
        "def train_model(net, epochs, loss_fn, optimizer):\n",
        "    \n",
        "    # 学習に使用する機器(device)の設定\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # モデルを設定した機器(device)に移動する\n",
        "    net.to(device)\n",
        "    \n",
        "    # ベストスコアの初期値\n",
        "    best_iou = 0.0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # 現在のエポック数の出力\n",
        "        print(f'Epoch: {epoch+1} / {epochs}')\n",
        "        print('--------------------------')\n",
        "\n",
        "        # 毎エポック: 学習、検証を別々に行う　phaseで学習or検証を参照\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            # 学習モード、検証モードの切替\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "            else:\n",
        "                net.eval()\n",
        "                                \n",
        "            # 損失値のリセット\n",
        "            epoch_loss = 0.0\n",
        "            # 予測値リストのリセット\n",
        "            pred_list = []\n",
        "            # 正解値リストのリセット\n",
        "            true_list = []\n",
        "            \n",
        "            # dataloaderから、ミニバッチ(batch_size)単位でのデータの読み込み\n",
        "            for images, labels in dataloaders_dict[phase]:\n",
        "                \n",
        "                # 入力データ、正解ラベルをモデルと同じdeviceへ移動\n",
        "                images = images.float().to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # 勾配情報の初期化\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # 学習時のみ勾配情報を有効に\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "    \n",
        "                    # モデルによる計算\n",
        "                    outputs = net(images)\n",
        "                    # 損失値の計算\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    # 予測ラベルの算出\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    # 学習時のみ、バックプロパゲーションとパラメータ更新\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                    # 損失値の追加\n",
        "                    epoch_loss += loss.item() * images.size(0)\n",
        "\n",
        "                    # 予測ラベルの追加\n",
        "                    preds = preds.to('cpu').numpy()\n",
        "                    pred_list.extend(preds)\n",
        "\n",
        "                    # 正解ラベルの追加\n",
        "                    labels = labels.to('cpu').numpy()\n",
        "                    true_list.extend(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSU2V5MzygTo"
      },
      "source": [
        "### 2-5.途中過程における評価スコアの表示設定を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo4-6K0UygXp"
      },
      "source": [
        "**評価指標の出力**\n",
        "**１データあたりの損失の平均値の集計**\n",
        "\n",
        "\n",
        "```\n",
        "# 1エポック内における損失値の平均\n",
        "epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "```\n",
        "\n",
        "**IoU(Intersection over Union)の算出**\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 混同行列の各値の算出\n",
        "tn, fp, fn, tp = confusion_matrix(true_list, pred_list).flatten()\n",
        "\n",
        "# IoUの算出\n",
        "epoch_iou = tp / (tp + fp + fn)\n",
        "```\n",
        "\n",
        "**出力の設定**\n",
        "\n",
        "\n",
        "```\n",
        "# 各評価スコアの出力\n",
        "print(f'{phase} Loss: {epoch_loss:.4f} IoU: {epoch_iou:.4f})\n",
        "```\n",
        "\n",
        "**モデルのパラメータ保存の設定**\n",
        "\n",
        "\n",
        "```\n",
        "# 検証時、検証スコアとベストスコアの大小比較を行う\n",
        "if (phase == 'val') and (epoch_iou > best_iou):\n",
        "\n",
        "    ## 検証スコアが上回った場合のみ以下の処理を行う。\n",
        "\n",
        "    # ベストスコアの更新\n",
        "    best_iou = epoch_iou\n",
        "\n",
        "    # パラメータの名前として、エポック番号とIoU値を指定\n",
        "    param_name = f'Epoch{epoch+1}_iou_{epoch_iou:.4f}.pth'\n",
        "\n",
        "    # パラメータの保存\n",
        "    torch.save(net.state_dict(), param_name)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOVSbp-Fzfy1"
      },
      "source": [
        "def train_model(net, epochs, loss_fn, optimizer):\n",
        "    \n",
        "    # 学習に使用する機器(device)の設定\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # モデルを設定した機器(device)に移動する\n",
        "    net.to(device)\n",
        "    \n",
        "    # ベストスコアの初期値\n",
        "    best_iou = 0.0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # 現在のエポック数の出力\n",
        "        print(f'Epoch: {epoch+1} / {epochs}')\n",
        "        print('--------------------------')\n",
        "\n",
        "        # 毎エポック: 学習、検証を別々に行う　phaseで学習or検証を参照\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            # 学習モード、検証モードの切替\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "            else:\n",
        "                net.eval()\n",
        "                                \n",
        "            # 損失値のリセット\n",
        "            epoch_loss = 0.0\n",
        "            # 予測値リストのリセット\n",
        "            pred_list = []\n",
        "            # 正解値リストのリセット\n",
        "            true_list = []\n",
        "            \n",
        "            # dataloaderから、ミニバッチ(batch_size)単位でのデータの読み込み\n",
        "            for images, labels in dataloaders_dict[phase]:\n",
        "                \n",
        "                # 入力データ、正解ラベルをモデルと同じdeviceへ移動\n",
        "                images = images.float().to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # 勾配情報の初期化\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # 学習時のみ勾配情報を有効に\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "    \n",
        "                    # モデルによる計算\n",
        "                    outputs = net(images)\n",
        "                    # 損失値の計算\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    # 予測ラベルの算出\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    # 学習時のみ、バックプロパゲーションとパラメータ更新\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                    # 損失値の追加\n",
        "                    epoch_loss += loss.item() * images.size(0)\n",
        "\n",
        "                    # 予測ラベルの追加\n",
        "                    preds = preds.to('cpu').numpy()\n",
        "                    pred_list.extend(preds)\n",
        "\n",
        "                    # 正解ラベルの追加\n",
        "                    labels = labels.to('cpu').numpy()\n",
        "                    true_list.extend(labels)\n",
        "              \n",
        "            # 1エポック内における損失値の平均\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            \n",
        "            # 混同行列の各値の算出\n",
        "            tn, fp, fn, tp = confusion_matrix(true_list, pred_list).flatten()\n",
        "\n",
        "            # IoUの算出\n",
        "            epoch_iou = tp / (tp + fp + fn)\n",
        "            \n",
        "            # 各評価スコアの出力\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} IoU: {epoch_iou:.4f}')  \n",
        "            \n",
        "            # 検証時、検証スコアとベストスコアの大小比較を行う\n",
        "            if (phase == 'val') and (epoch_iou > best_iou):\n",
        "\n",
        "                ## 検証スコアが上回った場合のみ以下の処理を行う。\n",
        "\n",
        "                # ベストスコアの更新\n",
        "                best_iou = epoch_iou\n",
        "                # パラメータの名前を指定\n",
        "                param_name = f'Epoch{epoch+1}_iou_{epoch_iou:.4f}.pth'\n",
        "                # パラメータの保存\n",
        "                torch.save(net.state_dict(), param_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzLfyRd2bpwY"
      },
      "source": [
        "## 3.モデルの学習と推論を実行する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "220pAr9izjy9"
      },
      "source": [
        "### 3-1.モデルの学習を実行する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ImWN7DOzj3d"
      },
      "source": [
        "**train_model()関数が受け取る引数**\n",
        "\n",
        "\n",
        "```\n",
        "*   net: モデル\n",
        "*   epochs: 学習、検証を行うエポック数\n",
        "*   loss_fn: 損失関数\n",
        "*   optimizer: 最適化手法\n",
        "```\n",
        "\n",
        "**モデル、損失関数、最適化手法については、すでに以下のように設定済み**\n",
        "\n",
        "\n",
        "```\n",
        "# モデルの設定\n",
        "net = preresnet.preresnet(depth=20)\n",
        "net.conv1 = nn.Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "net.fc = nn.Linear(in_features=64, out_features=2, bias=True)\n",
        "\n",
        "# 損失関数の設定\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の設定\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b68OY6p0cB3"
      },
      "source": [
        "def train_model(net, epochs, loss_fn, optimizer):\n",
        "    \n",
        "    # 学習に使用する機器(device)の設定\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # モデルを設定した機器(device)に移動する\n",
        "    net.to(device)\n",
        "    \n",
        "    # ベストスコアの初期値\n",
        "    best_iou = 0.0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "    \n",
        "        # 現在のエポック数の出力\n",
        "        print(f'Epoch: {epoch+1} / {epochs}')\n",
        "        print('--------------------------')\n",
        "\n",
        "        # 毎エポック: 学習、検証を別々に行う　phaseで学習or検証を参照\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            # 学習モード、検証モードの切替\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "            else:\n",
        "                net.eval()\n",
        "                                \n",
        "            # 損失値のリセット\n",
        "            epoch_loss = 0.0\n",
        "            # 予測値リストのリセット\n",
        "            pred_list = []\n",
        "            # 正解値リストのリセット\n",
        "            true_list = []\n",
        "            \n",
        "            # dataloaderから、ミニバッチ(batch_size)単位でのデータの読み込み\n",
        "            for images, labels in dataloaders_dict[phase]:\n",
        "                \n",
        "                # 入力データ、正解ラベルをモデルと同じdeviceへ移動\n",
        "                images = images.float().to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # 勾配情報の初期化\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # 学習時のみ勾配情報を有効に\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "    \n",
        "                    # モデルによる計算\n",
        "                    outputs = net(images)\n",
        "                    # 損失値の計算\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    # 予測ラベルの算出\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    # 学習時のみ、バックプロパゲーションとパラメータ更新\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        \n",
        "                    # 損失値の追加\n",
        "                    epoch_loss += loss.item() * images.size(0)\n",
        "\n",
        "                    # 予測ラベルの追加\n",
        "                    preds = preds.to('cpu').numpy()\n",
        "                    pred_list.extend(preds)\n",
        "\n",
        "                    # 正解ラベルの追加\n",
        "                    labels = labels.to('cpu').numpy()\n",
        "                    true_list.extend(labels)\n",
        "              \n",
        "            # 1エポック内における損失値の平均\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            \n",
        "            # 混同行列の各値の算出\n",
        "            tn, fp, fn, tp = confusion_matrix(true_list, pred_list).flatten()\n",
        "            # IoUの算出\n",
        "            epoch_iou = tp / (tp + fp + fn)\n",
        "            \n",
        "            # 各評価スコアの出力\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} IoU: {epoch_iou:.4f}')            \n",
        "            # 検証時、検証スコアとベストスコアの大小比較を行う\n",
        "            if (phase == 'val') and (epoch_iou > best_iou):\n",
        "\n",
        "                ## 検証スコアが上回った場合のみ以下の処理を行う。\n",
        "\n",
        "                # ベストスコアの更新\n",
        "                best_iou = epoch_iou\n",
        "                # パラメータの名前を指定\n",
        "                param_name = f'Epoch{epoch+1}_iou_{epoch_iou:.4f}.pth'\n",
        "                # パラメータの保存\n",
        "                torch.save(net.state_dict(), param_name)\n",
        "                \n",
        "# モデルの構築\n",
        "net = preresnet.preresnet(depth=20)\n",
        "net.conv1 = nn.Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "net.fc = nn.Linear(in_features=64, out_features=2, bias=True)\n",
        "\n",
        "# 損失関数、最適化手法の設定\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "# エポック数の指定\n",
        "epochs = 1\n",
        "\n",
        "# 学習の実行\n",
        "train_model(net=net, epochs=epochs, loss_fn=loss_fn, optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2wqXceb0iUO"
      },
      "source": [
        "### 3-2.学習ログを確認する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjeYqwQl0iXS"
      },
      "source": [
        "### 3-3.未知のデータに対する推論を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q4Qzz0402wi"
      },
      "source": [
        "*学習済みの重みをロードする***\n",
        "\n",
        "\n",
        "```\n",
        "# 学習済みパラメータの読み込み\n",
        "trained_params = torch.load('Epoch1_iou_0.0444.pth', map_location=device)\n",
        "\n",
        "# モデルにパラメータをロード\n",
        "net.load_state_dict(trained_params)\n",
        "```\n",
        "\n",
        "**推論に使用するデータ**\n",
        "\n",
        "\n",
        "```\n",
        "# test_master.csvの読み込み\n",
        "test_master = pd.read_csv('test_master.csv')\n",
        "```\n",
        "\n",
        "**テスト用データセットの作成**\n",
        "\n",
        "\n",
        "```\n",
        "# 入力データ、ダミーラベルの設定\n",
        "x_test = test_master['file_name'].values\n",
        "dummy = test_master['flag'].values\n",
        "\n",
        "# データセットの設定\n",
        "test_dataset = SatelliteDataset(x_test, dummy, phase='val')\n",
        "\n",
        "# データローダーの設定\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "```\n",
        "\n",
        "**推論の実行**\n",
        "\n",
        "\n",
        "```\n",
        "# 予測を行うdevice(CPU or GPU)の指定\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 予測ラベルを格納するリストを初期化\n",
        "pred_list = []\n",
        "\n",
        "# test_dataloaderから、ミニバッチ単位でデータを読み込む\n",
        "for images, _ in test_dataloader:\n",
        "\n",
        "    # 入力データをdeviceへ\n",
        "    images = images.to('device')\n",
        "\n",
        "    # モデルによる変換\n",
        "    outputs = net(images)\n",
        "\n",
        "    # 出力値を予測値へ変換\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    preds = preds.to('cpu').numpy()\n",
        "\n",
        "    # 予測値をリストに追加\n",
        "    pred_list.extend(preds)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ziCibAD1VX_"
      },
      "source": [
        "# 予測を行うdevice(CPU or GPU)の指定\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 学習済みパラメータの読み込み\n",
        "trained_params = torch.load('Epoch1_iou_0.0444.pth', map_location=device)\n",
        "# モデルにパラメータをロード\n",
        "net.load_state_dict(trained_params)\n",
        "\n",
        "# test_master.csvの読み込み\n",
        "test_master = pd.read_csv('test_master.csv')\n",
        "\n",
        "# 入力データ、ダミーラベルの設定\n",
        "x_test = test_master['file_name'].values\n",
        "dummy = test_master['flag'].values\n",
        "\n",
        "# データセットの設定\n",
        "test_dataset = SatelliteDataset(x_test, dummy, phase='val')\n",
        "# データローダーの設定\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 予測ラベルを格納するリストを初期化\n",
        "pred_list = []\n",
        "# test_dataloaderから、ミニバッチ単位でデータを読み込む\n",
        "for images, _ in test_dataloader:\n",
        "\n",
        "    # 入力データをdeviceへ\n",
        "    images = images.float().to(device)\n",
        "    # モデルによる変換\n",
        "    outputs = net(images)\n",
        "    # 出力値を予測値へ変換\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    preds = preds.to('cpu').numpy()\n",
        "    # 予測値をリストに追加\n",
        "    pred_list.extend(preds)\n",
        "    \n",
        "print(pred_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhIH3IpERU0q"
      },
      "source": [
        "# [5]予測精度の改善"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-hsmlYDb5cy"
      },
      "source": [
        "## 1.Data Augmentationとは"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBhqkkeT2DTT"
      },
      "source": [
        "### 1-1.Data Augmentationとは"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK_g9sW-2Dew"
      },
      "source": [
        "**画像データにおけるData Augmentationの方法**\n",
        "\n",
        "\n",
        "```\n",
        "*   水平フリップ(水平方向に画像を反転する)\n",
        "*   垂直フリップ(垂直方向に画像を反転する)\n",
        "*   回転(画像を回転させる)\n",
        "*   ズーム(画像の一部にフォーカスする)\n",
        "*   一部領域の消去(データ内の一部矩形領域を消去する)\n",
        "```\n",
        "\n",
        "**Data Augmentationを行う上での注意点**\n",
        "\n",
        "\n",
        "```\n",
        "変更を加えたあとでもデータの本来の性質が保たれているか\n",
        "```\n",
        "\n",
        "**今回適用できるデータ拡張**\n",
        "\n",
        "\n",
        "```\n",
        "*   水平フリップ\n",
        "*   垂直フリップ\n",
        "*   回転(90度, 180度, 270度)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnA0OeAG3E8j"
      },
      "source": [
        "### 1-2.PyTorchにおけるData Augmentationの実装方法を知る"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot2ufr_03JML"
      },
      "source": [
        "**PyTorchに用意されているData Augmentation用クラス**\n",
        "\n",
        "\n",
        "```\n",
        "*   水平フリップ: torchvision.transforms.RandomHorizontalFlip\n",
        "*   垂直フリップ: torchvision.transforms.RandomVerticalFlip\n",
        "*   回転: torchvision.transforms.RandomRotation\n",
        "```\n",
        "\n",
        "**TTA (Test Time Augmentation)**\n",
        "\n",
        "\n",
        "```\n",
        "*   推論時にもData Augmentationを行う手法\n",
        "*   各データを水増し(Data Augmentation)した上でそれぞれ推論を行い、出力された結果の平均値や多数決をとって、最終的な予測結果とするもの\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJZdeJo5b5gF"
      },
      "source": [
        "## 2.Data Augmentationクラスを作成する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y2MFP0d3mrV"
      },
      "source": [
        "### 2-1.各Data Augmentation手法に共通する設定を学ぶ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDGeuLYJ3mvQ"
      },
      "source": [
        "**各Data Augmentationクラスの実装をする際に共通するもの**\n",
        "\n",
        "\n",
        "```\n",
        "*   クラスの設計\n",
        "*   Data Augmentation処理を実行する確率の設定\n",
        "```\n",
        "\n",
        "**Data Augmentationクラスの設計**\n",
        "\n",
        "\n",
        "```\n",
        "class Normalize():\n",
        "    def __call__(self, image):\n",
        "        max = 30000\n",
        "        min = 5000\n",
        "        image_normalized = np.clip(image, min, max)\n",
        "        image_normalized = (image_normalized - min) / (max - min)\n",
        "        return image_normalized\n",
        "```\n",
        "\n",
        "**Data Augmentation処理を実行する確率の設定**\n",
        "\n",
        "\n",
        "```\n",
        "*   Data Augmentation処理を行う\n",
        "*   Data Augmentation処理を行わない\n",
        "を、一定の確率で分岐するように設定\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "# randomライブラリのインポート\n",
        "import random\n",
        "\n",
        "# 変数pにrandom.random()にて0.0以上1.0未満の浮動小数点数をランダムに生成\n",
        "p = random.random()\n",
        "\n",
        "# 50%の確率で分岐\n",
        "if p < 0.5:\n",
        "    print('Data Augmentation実行')\n",
        "else:\n",
        "    print('処理を行わず入力データをそのまま返り値とする')\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zaGicEX4ZQg"
      },
      "source": [
        "### 2-2.水平フリップ(Horizontal Flip)を実装する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzRt7V7M4it0"
      },
      "source": [
        "**np.fliplr()による水平フリップ処理の実装**\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "# np.fliplr()関数で、水平フリップ処理を適用する\n",
        "flipped_image = np.fliplr(image)\n",
        "```\n",
        "\n",
        "**fliplr()関数**\n",
        "\n",
        "\n",
        "```\n",
        "*   l: left(左)\n",
        "*   r: right(右)\n",
        "```\n",
        "\n",
        "**フリップ(反転)処理を行う際の注意点**\n",
        "\n",
        "\n",
        "```\n",
        "上記のようなフリップ処理を行った画像をToTensor()クラスにてtorch.Tensor()型に変換しようとするとエラーが発生\n",
        "\n",
        "# np.fliplr()関数で、水平フリップ処理を適用する\n",
        "flipped_image = np.fliplr(image).copy()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBV_TMpJ5d5P"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 画像の読み込み\n",
        "image = io.imread('dog.png')\n",
        "\n",
        "# 水平フリップクラスの設定\n",
        "class HorizontalFlip():\n",
        "    def __call__(self, image):\n",
        "        p = random.random()\n",
        "        \n",
        "        # 水平フリップを適用する(50%)\n",
        "        if p < 0.5:\n",
        "            image_transformed = np.____(image).copy()\n",
        "            return image_transformed\n",
        "        # 水平フリップを適用しない(50%)\n",
        "        else:\n",
        "            return image\n",
        "        \n",
        "horizontal_flip = HorizontalFlip()\n",
        "\n",
        "flipped_image = horizontal_flip(image)\n",
        "\n",
        "plt.imshow(flipped_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COi1Tjqs5IVs"
      },
      "source": [
        "### 2-3.垂直フリップ(Vertical Flip)を実装する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ9k36jh5Mpu"
      },
      "source": [
        "**np.flipud()による垂直フリップ処理の実装**\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "# np.flipud()関数で、垂直フリップ処理を適用する\n",
        "flipped_image = np.flipud(image)\n",
        "```\n",
        "\n",
        "**flipud()関数**\n",
        "\n",
        "\n",
        "```\n",
        "*   u: up(上)\n",
        "*   d: down(下)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjQJA3b25sjL"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 画像の読み込み\n",
        "image = io.imread('dog.png')\n",
        "\n",
        "# 垂直フリップクラスの設定\n",
        "class VerticalFlip():\n",
        "    def __call__(self, image):\n",
        "        p = random.random()\n",
        "        \n",
        "        # 垂直フリップを適用する(50%)\n",
        "        if p < 0.5:\n",
        "            image_transformed = np.flipud(image).copy()\n",
        "            return image_transformed\n",
        "            \n",
        "        # 垂直フリップを適用しない(50%)\n",
        "        else:\n",
        "            return image\n",
        "        \n",
        "vertical_flip = VerticalFlip()\n",
        "\n",
        "flipped_image = vertical_flip(image)\n",
        "\n",
        "plt.imshow(flipped_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jajuP6OC5xXU"
      },
      "source": [
        "### 2-4.回転(Rotate)を実装する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CohvkTC250A1"
      },
      "source": [
        "**回転とは**\n",
        "\n",
        "\n",
        "```\n",
        "from skimage import io\n",
        "\n",
        "# scipy.ndimageのインポート\n",
        "from scipy import ndimage\n",
        "\n",
        "image = io.imread('train_0.tif')\n",
        "\n",
        "# 画像を時計回りに90度回転させる\n",
        "rotated_image = ndimage.rotate(image, 90)\n",
        "```\n",
        "\n",
        "**ndimage.rotate()関数の引数**\n",
        "\n",
        "\n",
        "```\n",
        "*   第一引数: 元の画像\n",
        "*   第二引数: 回転させたい角度(反時計回り)\n",
        "```\n",
        "\n",
        "**回転処理を行う角度の指定**\n",
        "\n",
        "\n",
        "```\n",
        "*   0度(回転を加えない)\n",
        "*   90度\n",
        "*   180度\n",
        "*   270度\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlK36r676c0K"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from skimage import io\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = io.imread('dog.png')\n",
        "\n",
        "# 回転処理を行う前処理クラスの指定\n",
        "class Rotate():\n",
        "    \n",
        "    def __call__(self, image):\n",
        "        p = random.random()\n",
        "        \n",
        "        # 回転処理を加えない場合(25%)\n",
        "        if p < 0.25:\n",
        "            return image\n",
        "        \n",
        "        # ９０度回転を行う場合(25%)\n",
        "        elif p < 0.5:\n",
        "            image_transformed = ndimage.rotate(image, 90)\n",
        "            return image_transformed\n",
        "        \n",
        "        # １８０度回転を行う場合(25%)\n",
        "        elif p < 0.75:\n",
        "            image_transformed = ndimage.rotate(image, 180)\n",
        "            return image_transformed\n",
        "        \n",
        "        # ２７０度回転を行う場合(25%)\n",
        "        else:\n",
        "            image_transformed = ndimage.rotate(image, 270)\n",
        "            return image_transformed\n",
        "        \n",
        "rotate = Rotate()\n",
        "\n",
        "rotated_image = rotate(image)\n",
        "\n",
        "plt.imshow(rotated_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr4-ISf86nYy"
      },
      "source": [
        "### 2-5.前処理にData Augmentationを追加する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2lZj2LR6xZQ"
      },
      "source": [
        "**下記３つのData Augmentationクラスを追加**\n",
        "\n",
        "\n",
        "```\n",
        "*   HorizontalFlip()\n",
        "*   VerticalFlip()\n",
        "*   Rotate()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t694lj2Q7AtU"
      },
      "source": [
        "transform = {\n",
        "    \n",
        "    # 学習時のみ、３つのData Augmentation処理を行う。\n",
        "    'train': transforms.Compose([\n",
        "        Normalize(),\n",
        "        HorizontalFlip(),\n",
        "        VerticalFlip(),\n",
        "        Rotate(),\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "    \n",
        "    'val': transforms.Compose([\n",
        "        Normalize(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyeD5hMq7HKS"
      },
      "source": [
        "### 2-6.Data Augmentationを含めてモデルの学習を行う"
      ]
    }
  ]
}