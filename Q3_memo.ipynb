{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3_memo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmMkNVilY5B0S5AzYs/M2V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXXdTiIlu8Bp"
      },
      "source": [
        "# データの読み込み\n",
        "from PIL import Image\n",
        "im = Image.open('cast_ok_0_1057.jpeg')\n",
        "\n",
        "# Q1\n",
        "print(im.format)\n",
        "\n",
        "# Q2\n",
        "print(im.size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPIWmWMav5Bh"
      },
      "source": [
        "# matplotlibライブラリ内のpyplotモジュールをインポート\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PILライブラリのImageモジュールをインポート\n",
        "from PIL import Image\n",
        "\n",
        "# 画像の読み込み\n",
        "img = Image.open('cast_def_0_1055.jpeg')\n",
        "\n",
        "# 画像の表示\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI86FW76v5yZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# 画像の読み込み\n",
        "\n",
        "im1 = Image.open('cast_ok_0_1057.jpeg')\n",
        "im2 = Image.open('cast_ok_0_1028.jpeg')\n",
        "im3 = Image.open('cast_def_0_1055.jpeg')\n",
        "im4 = Image.open('cast_def_0_1056.jpeg')\n",
        "\n",
        "# 画像表示\n",
        "# 1行4列の1番目\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(im1)\n",
        "plt.title('OK1')\n",
        "\n",
        "# 1行4列の2番目\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(im2)\n",
        "plt.title('OK2')\n",
        "\n",
        "# 1行4列の3番目\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(im3)\n",
        "plt.title('NG2')\n",
        "\n",
        "# 1行4列の4番目\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(im4)\n",
        "plt.title('NG2')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm7IYPFZv51S"
      },
      "source": [
        "# ライブラリの読み込み\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# 画像の読み込み\n",
        "im = Image.open('cast_def_0_105.jpeg')\n",
        "\n",
        "# 図形描画\n",
        "d = ImageDraw.Draw(im)\n",
        "d.rectangle(xy=[(40, 80), (110,140)], outline='red', width=3)\n",
        "\n",
        "# 図形の表示\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GraGcbvFv53m"
      },
      "source": [
        "# ライブラリの読み込み\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# 画像の読み込み\n",
        "im = Image.open('cast_def_0_131.jpeg')\n",
        "\n",
        "# 図形描画\n",
        "d = ImageDraw.Draw(im)\n",
        "d.ellipse(xy=[(10, 10),(280, 280)], outline='red',width=3)\n",
        "\n",
        "# 図形の表示\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Z2bufjv56D"
      },
      "source": [
        "# ライブラリの読み込み\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# 画像の読み込み\n",
        "im = Image.open('cast_def_0_105.jpeg')\n",
        "\n",
        "new_img = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "# 画像表示\n",
        "plt.imshow(new_img)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhWkM1M9v58W"
      },
      "source": [
        "#ライブラリの読み込み\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image,ImageFilter\n",
        "\n",
        "# 画像の読み込み\n",
        "im = Image.open('cast_def_0_131.jpeg')\n",
        "\n",
        "# 【処理1】画像のピクセル値を全て1.9倍にコントラスト調整\n",
        "temp_im = im.point(lambda x: x * 1.9)\n",
        "\n",
        "# 【処理2】強度9のぼかし（ガウス）を実施\n",
        "new_im = temp_im.filter(ImageFilter.GaussianBlur(9))\n",
        "\n",
        "# 画像表示\n",
        "plt.imshow(new_im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGmuNEpFv5-4"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image,ImageFilter\n",
        "\n",
        "# 画像の読み込み\n",
        "im = Image.open('cast_def_0_1056.jpeg')\n",
        "\n",
        "# フィルター処理\n",
        "new_im  = im.filter(ImageFilter.FIND_EDGES)\n",
        "\n",
        "# 画像表示\n",
        "plt.imshow(new_im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_SZwTpNv6BS"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import os\n",
        "\n",
        "# 現在の作業ディレクトリのファイル一覧を変数filesに代入し、一覧を表示してください\n",
        "files = os.listdir('./')\n",
        "print(files)\n",
        "\n",
        "# 現在の作業ディレクトリのファイル一覧が代入されている変数filesのデータ型を表示してください\n",
        "print(os.path.getsize('image_data.zip'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zDNUzHTv6Du"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# zip解凍用の関数定義\n",
        "def unzip_dataset(INPATH,OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "\n",
        "# zip解凍(※数秒から数十秒かかる場合があります)\n",
        "unzip_dataset(INPATH='./image_data.zip',OUTPATH='./')\n",
        "\n",
        "# osを使って、ファイルの一覧確認\n",
        "print(os.listdir('./image_data/train/ok'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5OGBJ1Qv6GL"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# ライブラリのインポート\n",
        "def unzip_dataset(PATH):\n",
        "    with zipfile.ZipFile(PATH) as zf:\n",
        "        zf.extractall()\n",
        "\n",
        "# zip解凍(※数秒から数十秒かかる場合があります)\n",
        "unzip_dataset(PATH='./image_data.zip')\n",
        "\n",
        "# 画像一覧のリスト取得\n",
        "ok_image_name_list = os.listdir('./image_data/train/ok')\n",
        "ng_image_name_list = os.listdir('./image_data/train/ng')\n",
        "\n",
        "# リストの大きさ表示\n",
        "print(len(ok_image_name_list))\n",
        "print(len(ng_image_name_list))\n",
        "\n",
        "# 重複を抜いたリストの大きさ表示\n",
        "print(len(set(ok_image_name_list)))\n",
        "print(len(set(ng_image_name_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO2vQouPv6Ik"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from torchvision import transforms\n",
        "\n",
        "# transformsの定義\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(print(data_transforms))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko1iVmHgv6K3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABR2A-sIv6Nk"
      },
      "source": [
        "import zipfile\n",
        "from torchvision import transforms,datasets\n",
        "\n",
        "def unzip_dataset(INPATH,OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "\n",
        "# zip解凍（※operation初回のみ必要）\n",
        "unzip_dataset(INPATH='./image_data.zip',OUTPATH='./')\n",
        "\n",
        "\n",
        "# transforms定義\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# dataset作成\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder('./image_data/train',data_transforms['train']),\n",
        "    'val': datasets.ImageFolder('./image_data/val',data_transforms['val'])\n",
        "}\n",
        "\n",
        "print(image_datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGrIiiWnv6P5"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "# 事前学習無のResNet18作成\n",
        "model_ft = models.resnet18(pretrained=False)\n",
        "\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRyJlByiv6SM"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "\n",
        "# 定数設定\n",
        "device = \"cpu\"\n",
        "TARGET_NUM = 10\n",
        "\n",
        "# モデル作成関数の定義\n",
        "def get_model(target_num,isPretrained=False):\n",
        "    \"\"\"for get model\"\"\"\n",
        "    \n",
        "    model_ft = models.resnet18(pretrained=isPretrained)\n",
        "    model_ft.fc = nn.Linear(512, target_num)\n",
        "    model_ft = model_ft.to(device)\n",
        "    return model_ft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3J5T2mv6Uc"
      },
      "source": [
        "#ライブラリのインポート\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "\n",
        "# 定数設定\n",
        "device = \"cpu\"\n",
        "TARGET_NUM = 2\n",
        "\n",
        "# モデル定義\n",
        "def get_model(target_num,isPretrained=False):\n",
        "    \"\"\"for get model\"\"\"\n",
        "\n",
        "    model_ft = models.resnet18(pretrained=isPretrained)\n",
        "    model_ft.fc = nn.Linear(512, target_num)\n",
        "    model_ft = model_ft.to(device)\n",
        "    return model_ft\n",
        "\n",
        "\n",
        "# モデルのインスタンス作成\n",
        "model_ft = get_model(target_num=TARGET_NUM,isPretrained=False)\n",
        "\n",
        "# 最適化関数定義\n",
        "optimizer = optim.SGD(model_ft.parameters(),lr=0.001, momentum=0.9)\n",
        "\n",
        "# loss関数定義\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejHYYEPrv6XC"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "DEVICE= \"cpu\"\n",
        "\n",
        "# モデル学習用関数\n",
        "def train_model(model, criterion, optimizer, num_epochs=5,is_saved = False):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # エポック数だけ下記工程の繰り返し\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            print('{}:フェイズ'.format(phase))\n",
        "\n",
        "            # 訓練フェイズと検証フェイズの切り替え\n",
        "            if phase == 'train':\n",
        "                model.train() \n",
        "            else:\n",
        "                model.eval()  \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # dataloadersからバッチサイズだけデータ取り出し、下記工程（1−5）の繰り返し\n",
        "            for i,(inputs, labels) in enumerate(image_dataloaders[phase]):\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "\n",
        "                # 1. optimizerの勾配初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 2.モデルに入力データをinputし、outputを取り出す\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                # 3. outputと正解ラベルから、lossを算出\n",
        "                loss = criterion(outputs, labels)\n",
        "                print('   loaders:{}回目'.format(i+1)  ,'   loss:{}'.format(loss))\n",
        "\n",
        "                if phase == 'train':                        \n",
        "                    # 4. 誤差逆伝播法により勾配の算出\n",
        "                    loss.backward()\n",
        "                    # 5. optimizerのパラメータ更新\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # C. 今までのエポックでの精度よりも高い場合はモデルの保存\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                if(is_saved):\n",
        "                    torch.save(model.state_dict(), './original_model_{}.pth'.format(epoch))\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhCfMQ6haZeW"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "DEVICE= \"cpu\"\n",
        "\n",
        "# モデル訓練用関数\n",
        "def train_model(model, criterion, optimizer, num_epochs=5,is_saved = False):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # エポック数だけ下記工程の繰り返し\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            print('{}:フェイズ'.format(phase))\n",
        "\n",
        "            # 訓練フェイズと検証フェイズの切り替え\n",
        "            if phase == 'train':\n",
        "                model.train() \n",
        "            else:\n",
        "                model.eval()  \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # dataloadersからバッチサイズだけデータ取り出し、下記工程（1−5）の繰り返し\n",
        "            for i,(inputs, labels) in enumerate(image_dataloaders[phase]):\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "\n",
        "                # 1. optimizerの勾配初期化\n",
        "                optimizer.zero_grad()\n",
        "                    \n",
        "                # 2.モデルに入力データをinputし、outputを取り出す\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                # 3. outputと正解ラベルから、lossを算出\n",
        "                loss = criterion(outputs, labels)\n",
        "                print('   loaders:{}回目'.format(i+1)  ,'   loss:{}'.format(loss))\n",
        "\n",
        "                if phase == 'train':                        \n",
        "                    # 4. 誤差逆伝播法により勾配の算出\n",
        "                    loss.backward()\n",
        "                    # 5. optimizerのパラメータ更新\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # C. 今までのエポックでの精度よりも高い場合はモデルの保存\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                if(is_saved):\n",
        "                    torch.save(model.state_dict(), './original_model_{}.pth'.format(epoch))\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQ4A9bhaZkk"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "DEVICE= \"cpu\"\n",
        "\n",
        "# モデル訓練用関数\n",
        "def train_model(model, criterion, optimizer, num_epochs=5,is_saved = False):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # エポック数だけ下記工程の繰り返し\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            print('{}:フェイズ'.format(phase))\n",
        "\n",
        "            # 訓練フェイズと検証フェイズの切り替え\n",
        "            if phase == 'train':\n",
        "                model.train() \n",
        "            else:\n",
        "                model.eval()  \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # dataloadersからバッチサイズだけデータ取り出し、下記工程（1−5）の繰り返し\n",
        "            for i,(inputs, labels) in enumerate(image_dataloaders[phase]):\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "\n",
        "                # 1. optimizerの勾配初期化\n",
        "                optimizer.zero_grad()\n",
        "                    \n",
        "                # 2.モデルに入力データをinputし、outputを取り出す\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                # 3. outputと正解ラベルから、lossを算出\n",
        "                loss = criterion(outputs, labels)\n",
        "                print('   loaders:{}回目'.format(i+1)  ,'   loss:{}'.format(loss))\n",
        "\n",
        "                if phase == 'train':                        \n",
        "                    # 4. 誤差逆伝播法により勾配の算出\n",
        "                    loss.backward()\n",
        "                    # 5. optimizerのパラメータ更新\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # C. 今までのエポックでの精度よりも高い場合はモデルの保存\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                if(is_saved):\n",
        "                    torch.save(model.state_dict(), './original_model_{}.pth'.format(epoch))\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCWpelhIdIe1"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# zip解凍\n",
        "def unzip_dataset(INPATH,OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "        \n",
        "unzip_dataset(INPATH='./test_data.zip',OUTPATH='./')\n",
        "\n",
        "# DataFrame作成\n",
        "df_test = pd.DataFrame(data=os.listdir('./test_data/'))\n",
        "\n",
        "# カラム名変更\n",
        "df_test = df_test.rename(columns={0: 'filename'})\n",
        "\n",
        "# targetカラム作成\n",
        "df_test['target'] = 0\n",
        "df_test.loc[df_test['filename'].str.contains('ok'),'target'] = 1\n",
        "\n",
        "# csv保存\n",
        "df_test.to_csv('df_test.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67fj2Kfsdhnk"
      },
      "source": [
        "# ライブラリのインポート\n",
        "from torchvision import transforms\n",
        "\n",
        "# 推論用のtransforms作成\n",
        "test_transforms = transforms.Compose([\n",
        "               transforms.Resize(256),\n",
        "               transforms.ToTensor(),\n",
        "               transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHXSi5Ikem_E"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# zip解凍\n",
        "def unzip_dataset(INPATH,OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "        \n",
        "unzip_dataset(INPATH='./test_data.zip',OUTPATH='./')\n",
        "\n",
        "\n",
        "# dataset作成\n",
        "class Test_Datasets(Dataset):\n",
        "\n",
        "    def __init__(self, data_transform):\n",
        "        \n",
        "        self.df = pd.read_csv('./df_test.csv',names=['filename','target'])\n",
        "        self.data_transform = data_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        file = self.df['filename'][index]\n",
        "        image = Image.open('./test_data/'+ file)\n",
        "        image = self.data_transform(image)\n",
        "\n",
        "        return image,file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p4u8qb6fLQZ"
      },
      "source": [
        "# datasetのインスタンス作成\n",
        "test_dataset = Test_Datasets(data_transform=test_transforms)\n",
        "\n",
        "# dataloader作成\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                                batch_size=1 , \n",
        "                                                shuffle=False , \n",
        "                                                num_workers=0 , \n",
        "                                                drop_last=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjoS6qLPfrLT"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "DEVICE= \"cpu\"\n",
        "\n",
        "def get_model(target_num,isPretrained=False):\n",
        "    model_ft = models.resnet18(pretrained=isPretrained)\n",
        "    model_ft.fc = nn.Linear(512, target_num)\n",
        "    model_ft = model_ft.to(DEVICE)\n",
        "    return model_ft\n",
        "\n",
        "best_model = get_model(target_num=2)\n",
        "\n",
        "best_model.load_state_dict(torch.load('./original_model_33.pth', map_location=lambda storage, loc: storage), strict=True)\n",
        "\n",
        "print(best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VknEa25zhmH1"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "\n",
        "# 定数設定\n",
        "device = \"cpu\"\n",
        "TARGET_NUM = 2\n",
        "\n",
        "# モデル作成関数の定義\n",
        "def get_model(target_num,isPretrained=False):\n",
        "\n",
        "    if(isPretrained):\n",
        "        model_ft = models.resnet18(pretrained=False)\n",
        "        model_ft.load_state_dict(torch.load('./resnet18-5c106cde.pth', map_location=lambda storage, loc: storage), strict=True)\n",
        "    else:\n",
        "        model_ft = models.resnet18(pretrained=False)\n",
        "        \n",
        "    model_ft.fc = nn.Linear(512, target_num)\n",
        "    model_ft = model_ft.to(device)\n",
        "    return model_ft\n",
        "\n",
        "# 事前学習済みResNet18モデルのインスタンス作成\n",
        "pretrained_model = get_model(target_num=2,isPretrained=True)\n",
        "\n",
        "# 事前学習済みモデルを表示してください\n",
        "print(pretrained_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOm8kR0vhmVn"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import zipfile\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "#zipの解凍\n",
        "def unzip_dataset(INPATH,OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "\n",
        "unzip_dataset(INPATH='./augment_data.zip',OUTPATH='./')\n",
        "\n",
        "\n",
        "#データの出力用関数\n",
        "def show_augment(dataset):\n",
        "    for i in range(0, 6):\n",
        "        ax = plt.subplot(2, 3, i + 1)\n",
        "        plt.tight_layout()\n",
        "        ax.set_title(str(i))\n",
        "        plt.imshow(dataset[i][0])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Augmentation定義\n",
        "transform = transforms.Compose([\n",
        "                    transforms.RandomHorizontalFlip(p=0.5),\n",
        "                    transforms.RandomVerticalFlip(p=0.5),\n",
        "                       ])\n",
        "\n",
        "# データセット定義\n",
        "aug_dataset = datasets.ImageFolder(root='./augment_data/',transform=transform)\n",
        "\n",
        "# 画像表示\n",
        "show_augment(aug_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANT_XBdDjx__"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import zipfile\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import albumentations\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "def unzip_dataset(INPATH,OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "\n",
        "# zipの解凍\n",
        "unzip_dataset(INPATH='./augment_data.zip',OUTPATH='./')\n",
        "\n",
        "# ランダムグリッドシャッフル定義\n",
        "albu_transforms = albumentations.Compose([\n",
        "                          albumentations.RandomGridShuffle(grid=(1, 1), p=1.0), \n",
        "                        ])\n",
        "\n",
        "\n",
        "# albumentation用のデータ変換関数\n",
        "def albumentations_transform(image, transform=albu_transforms):\n",
        "    image_np = np.array(image)\n",
        "    augmented = transform(image=image_np)\n",
        "    image = Image.fromarray(augmented['image'])\n",
        "    return image\n",
        "\n",
        "# albumentation用のデータ変換関数\n",
        "data_transform = transforms.Compose([\n",
        "  transforms.Lambda(albumentations_transform),\n",
        "])\n",
        "\n",
        "# データセット定義\n",
        "dataset_augmentated = datasets.ImageFolder(root='./augment_data/', transform=data_transform)\n",
        "\n",
        "#データの出力用関数\n",
        "def show_augment(dataset):\n",
        "    for i in range(0, 6):\n",
        "        ax = plt.subplot(2, 3, i + 1)\n",
        "        plt.tight_layout()\n",
        "        ax.set_title(str(i))\n",
        "        plt.imshow(dataset[i][0])\n",
        "    plt.show()\n",
        "\n",
        "# 画像表示\n",
        "show_augment(dataset_augmentated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfEGu3zxkeYN"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import zipfile\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import albumentations\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "def unzip_dataset(INPATH,OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "\n",
        "# zipの解凍\n",
        "unzip_dataset(INPATH='./augment_data.zip',OUTPATH='./')\n",
        "\n",
        "#データの出力用関数\n",
        "def show_augment(dataset):\n",
        "    for i in range(0, 6):\n",
        "        ax = plt.subplot(2, 3, i + 1)\n",
        "        plt.tight_layout()\n",
        "        ax.set_title(str(i))\n",
        "        plt.imshow(dataset[i][0])\n",
        "    plt.show()\n",
        "\n",
        "# カットアウト定義\n",
        "albu_transforms = albumentations.Compose([\n",
        "                          albumentations.Cutout(num_holes=8, max_h_size=40, max_w_size=40, fill_value=0, p=1.0),\n",
        "                        ])\n",
        "\n",
        "\n",
        "# albumentation用のデータ変換関数\n",
        "def albumentations_transform(image, transform=albu_transforms):\n",
        "    image_np = np.array(image)\n",
        "    augmented = transform(image=image_np)\n",
        "    image = Image.fromarray(augmented['image'])\n",
        "    return image\n",
        "\n",
        "# albumentation用のデータ変換関数\n",
        "data_transform = transforms.Compose([\n",
        "  transforms.Lambda(albumentations_transform),\n",
        "])\n",
        "\n",
        "# データセット定義\n",
        "dataset_augmentated = datasets.ImageFolder(root='./augment_data/', transform=data_transform)\n",
        "\n",
        "# 画像表示\n",
        "show_augment(dataset_augmentated)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}