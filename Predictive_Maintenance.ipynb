{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predictive_Maintenance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNE1YcfL8UyOxqmYUtMz4Nq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU0ntHUVWvUh"
      },
      "source": [
        "# 工場設備の予知保全"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOOxDrCaWvcL"
      },
      "source": [
        "# [1] バルブ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Mi5NPtY0mr"
      },
      "source": [
        "## 1.音声データの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb3PAJxoZrF5"
      },
      "source": [
        "### 1-1.音声データの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq6PE6T2ZrJX"
      },
      "source": [
        "**音声データを扱うライブラリをインポート**\n",
        "\n",
        "```\n",
        "import librosa\n",
        "```\n",
        "**音声データを読み込む**\n",
        "\n",
        "```\n",
        "y, sr = librosa.load('ファイルパス', sr=None)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh9W7MDJaNOZ"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import librosa\n",
        "\n",
        "# ファイルパス\n",
        "file_path = 'dataset/valve/train/normal/00.wav'\n",
        "\n",
        "# データを読み込む\n",
        "y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "# 読み込んだデータの確認\n",
        "print(y)\n",
        "# yはnumpy.array型なのでshapeが使えます\n",
        "print(y.shape)\n",
        "print(sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh01N40xaZGN"
      },
      "source": [
        "### 1-2.秒数の確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uojd4xnraZLT"
      },
      "source": [
        "**1秒辺りのデータ数**\n",
        "\n",
        "```\n",
        "秒数 = データ数/サンプリングレート\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNopEkGnasFk"
      },
      "source": [
        "# ライブラリのインポート\n",
        "import librosa\n",
        "\n",
        "# ファイルパス\n",
        "file_path = 'dataset/valve/train/normal/00.wav'\n",
        "\n",
        "# データを読み込む\n",
        "y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "# 読み込んだデータの確認\n",
        "print(y)\n",
        "print(y.shape)\n",
        "print(sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CoQrxr3ausY"
      },
      "source": [
        "### 1-3.複数データの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZoVGTtaax66"
      },
      "source": [
        "**以下の引数を指定**\n",
        "\n",
        "```\n",
        "*   category：機械の種類\n",
        "*   train_test：学習データか評価データか\n",
        "*   label：正常音か異常音か\n",
        "```\n",
        "**対象ディレクトリのファイル名を全て取得**\n",
        "\n",
        "```\n",
        "import glob\n",
        "glob.glob('dataset/valve/train/normal/*.wav')\n",
        "```\n",
        "**文字列の前にfを付けることで、文字列内の一部を変数で置換**\n",
        "\n",
        "```\n",
        "f'dataset/{変数1}/{変数2}/{変数3}'\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob1JFkH3bbqc"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "category = 'valve'\n",
        "train_test = 'train'\n",
        "label = 'normal'\n",
        "\n",
        "def read_data(category, train_test, label):\n",
        "    # ファイル名一覧を取得\n",
        "    files = sorted(glob.glob(f\"dataset/{category}/{train_test}/{label}/*.wav\"))\n",
        "    dataset = []\n",
        "    # それぞれのファイルを読み込み\n",
        "    for file_name in files:\n",
        "        y, sr = librosa.load(file_name, sr = None)\n",
        "        dataset.append(y)\n",
        "    # np.array型に変換\n",
        "    return np.array(dataset)\n",
        "\n",
        "valve = read_data('valve', 'train', 'normal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFdH6UbBY0pK"
      },
      "source": [
        "## 2.教師あり学習による異常検知"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFCRzJ8JbiUF"
      },
      "source": [
        "### 2-1.音声データの可視化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EJJPxoFbpUP"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "正常音と異常音の違いを波形から確認する\n",
        "\n",
        "音声波形は横軸に時間、縦軸に振幅値をとる\n",
        "```\n",
        "**音声波形の描画**\n",
        "\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "y, sr = librosa.load('ファイルパス', sr=None)\n",
        "plt.plot(y)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhy82uIccEzE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 正常音の描画\n",
        "normal, sr = librosa.load('dataset/valve/train/normal/00.wav', sr=None)\n",
        "plt.plot(normal)\n",
        "plt.show()\n",
        "\n",
        "# 異常音の描画\n",
        "anomaly, sr = librosa.load('dataset/valve/train/anomaly/00.wav', sr=None)\n",
        "plt.plot(anomaly, color='orange')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szumYdE8cKGL"
      },
      "source": [
        "### 2-2.平均振幅の算出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_TB5ohrcUGs"
      },
      "source": [
        "**各データごとに振幅の平均値を計算し、データごとの平均値のヒストグラムを作成**\n",
        "\n",
        "```\n",
        "※音声データでは、振幅を2乗した値の平均値の平方根を平均振幅として扱う\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0omG8fb0cf9V"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "normal = read_data('valve','train','normal')\n",
        "# 正常音の平均振幅の算出\n",
        "normal_mean = np.sqrt(np.mean(normal**2,axis=1))\n",
        "\n",
        "anomaly = read_data('valve','train','anomaly')\n",
        "# 異常音の平均振幅の算出\n",
        "anomaly_mean = np.sqrt(np.mean(anomaly**2,axis=1))\n",
        "\n",
        "# ヒストグラムの描画\n",
        "plt.hist(normal_mean,alpha=0.5,label='normal')\n",
        "plt.hist(anomaly_mean,alpha=0.5,label='anomaly')\n",
        "plt.title('平均振幅のヒストグラム')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbCFeiXvcojn"
      },
      "source": [
        "### 2-3.ゼロクロス数の算出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKy3fiFi1IN9"
      },
      "source": [
        "**ゼロクロス数とはどのくらい正負が切り替わっているかを表すもの**\n",
        "\n",
        "```\n",
        "np.sum(librosa.zero_crossings(y))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "409do3Yb2jK8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "normal = read_data('valve','train','normal')\n",
        "# 正常音の平均振幅の算出\n",
        "normal_mean = np.sqrt(np.mean(normal**2,axis=1))\n",
        "\n",
        "# 正常音のゼロクロス数の算出\n",
        "normal_zc = np.sum(librosa.zero_crossings(normal),axis=1)\n",
        "print(normal_zc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u9-GADs2lWf"
      },
      "source": [
        "### 2-4.データフレームの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t4udBzT2vSa"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 学習データの読み込み\n",
        "train_normal = read_data('valve','train','normal')\n",
        "train_anomaly = read_data('valve','train','anomaly')\n",
        "train = np.concatenate([train_normal,train_anomaly])\n",
        "\n",
        "# 平均振幅、ゼロクロス数の算出\n",
        "train_mean = np.sqrt(np.mean(train**2,axis=1))\n",
        "train_zc = np.sum(librosa.zero_crossings(train),axis=1)\n",
        "\n",
        "# 平均振幅(mean)、ゼロクロス数(zc)、正常or異常(label)をカラムにもつDataFrameの作成\n",
        "train_df = pd.DataFrame()\n",
        "train_df['mean'] = train_mean\n",
        "train_df['zc'] = train_zc\n",
        "train_df['label'] = np.concatenate([np.zeros(len(train_normal)),np.ones(len(train_anomaly))])\n",
        "print(train_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzkLv2_z23hG"
      },
      "source": [
        "### 2-5.2値分類モデルの作成・予測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y_rBAy427uk"
      },
      "source": [
        "**モデルの作成から予測まで**\n",
        "\n",
        "```\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X,y)\n",
        "model.predict(X)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh8Kkx5A3G5r"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 学習データのDataFrameの作成\n",
        "train_normal = read_data('valve','train','normal')\n",
        "train_anomaly = read_data('valve','train','anomaly')\n",
        "train = np.concatenate([train_normal,train_anomaly])\n",
        "train_df = pd.DataFrame()\n",
        "train_df['mean']= np.sqrt(np.mean(train**2,axis=1))\n",
        "train_df['zc'] = np.sum(librosa.zero_crossings(train),axis=1)\n",
        "train_df['label'] = np.concatenate([np.zeros(len(train_normal)),np.ones(len(train_anomaly))])\n",
        "\n",
        "# 評価データのDataFrameの作成\n",
        "test_normal = read_data('valve','test','normal')\n",
        "test_anomaly = read_data('valve','test','anomaly')\n",
        "test = np.concatenate([test_normal,test_anomaly])\n",
        "test_df = pd.DataFrame()\n",
        "test_df['mean'] = np.sqrt(np.mean(test**2,axis=1))\n",
        "test_df['zc'] = np.sum(librosa.zero_crossings(test),axis=1)\n",
        "test_df['label'] = np.concatenate([np.zeros(len(test_normal)),np.ones(len(test_anomaly))])\n",
        "\n",
        "train_X, train_y = train_df[['mean','zc']], train_df['label']\n",
        "test_X, test_y = test_df[['mean','zc']], test_df['label']\n",
        "# モデルの作成\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "# 学習\n",
        "model.fit(train_X,train_y)\n",
        "# 予測\n",
        "pred = model.predict(test_X)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_7yCP973Nyd"
      },
      "source": [
        "### 2-6.予測精度の評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rekyBkX33Tbe"
      },
      "source": [
        "**混同行列をpythonで作成する**\n",
        "\n",
        "```\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_true=実際の値, y_pred=予測値)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbJHKHfv3fmc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 学習データのDataFrameの作成\n",
        "train_normal = read_data('valve','train','normal')\n",
        "train_anomaly = read_data('valve','train','anomaly')\n",
        "train = np.concatenate([train_normal,train_anomaly])\n",
        "train_df = pd.DataFrame()\n",
        "train_df['mean']= np.sqrt(np.mean(train**2,axis=1))\n",
        "train_df['zc'] = np.sum(librosa.zero_crossings(train),axis=1)\n",
        "train_df['label'] = np.concatenate([np.zeros(len(train_normal)),np.ones(len(train_anomaly))])\n",
        "\n",
        "# 評価データのDataFrameの作成\n",
        "test_normal = read_data('valve','test','normal')\n",
        "test_anomaly = read_data('valve','test','anomaly')\n",
        "test = np.concatenate([test_normal,test_anomaly])\n",
        "test_df = pd.DataFrame()\n",
        "test_df['mean'] = np.sqrt(np.mean(test**2,axis=1))\n",
        "test_df['zc'] = np.sum(librosa.zero_crossings(test),axis=1)\n",
        "test_df['label'] = np.concatenate([np.zeros(len(test_normal)),np.ones(len(test_anomaly))])\n",
        "\n",
        "train_X, train_y = train_df[['mean','zc']], train_df['label']\n",
        "test_X, test_y = test_df[['mean','zc']], test_df['label']\n",
        "# モデルの作成\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "# 学習\n",
        "model.fit(train_X,train_y)\n",
        "# 予測\n",
        "pred = model.predict(test_X)\n",
        "# 混同行列の作成\n",
        "print(confusion_matrix(test_y, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C4x8ICtWvlU"
      },
      "source": [
        "# [2] スライダー"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAz-IXKjY9CO"
      },
      "source": [
        "## 1.教師あり学習による異常検知"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAC3Dkh323U"
      },
      "source": [
        "### 1-1.教師あり学習による異常検知"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRI0s-Kv38-9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 学習データのDataFrameの作成\n",
        "train_normal = read_data('slider','train','normal')\n",
        "train_anomaly = read_data('slider','train','anomaly')\n",
        "train = np.concatenate([train_normal,train_anomaly])\n",
        "train_df = pd.DataFrame()\n",
        "train_df['mean']= np.sqrt(np.mean(train**2,axis=1))\n",
        "train_df['zc'] = np.sum(librosa.zero_crossings(train),axis=1)\n",
        "train_df['label'] = np.concatenate([np.zeros(len(train_normal)),np.ones(len(train_anomaly))])\n",
        "\n",
        "# 評価データのDataFrameの作成\n",
        "test_normal = read_data('slider','test','normal')\n",
        "test_anomaly = read_data('slider','test','anomaly')\n",
        "test = np.concatenate([test_normal,test_anomaly])\n",
        "test_df = pd.DataFrame()\n",
        "test_df['mean'] = np.sqrt(np.mean(test**2,axis=1))\n",
        "test_df['zc'] = np.sum(librosa.zero_crossings(test),axis=1)\n",
        "test_df['label'] = np.concatenate([np.zeros(len(test_normal)),np.ones(len(test_anomaly))])\n",
        "\n",
        "train_X, train_y = train_df[['mean','zc']], train_df['label']\n",
        "test_X, test_y = test_df[['mean','zc']], test_df['label']\n",
        "# モデルの作成\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "# 学習\n",
        "model.fit(train_X,train_y)\n",
        "# 予測\n",
        "pred = model.predict(test_X)\n",
        "# 混同行列の作成\n",
        "print(confusion_matrix(test_y, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j886u1Nf4H1G"
      },
      "source": [
        "### 1-2.評価データの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWF7ODOY4DZQ"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 学習データのDataFrameの作成\n",
        "train_normal = read_data('slider','train','normal')\n",
        "train_anomaly = read_data('slider','train','anomaly')\n",
        "train = np.concatenate([train_normal,train_anomaly])\n",
        "train_df = pd.DataFrame()\n",
        "train_df['mean']= np.sqrt(np.mean(train**2,axis=1))\n",
        "train_df['zc'] = np.sum(librosa.zero_crossings(train),axis=1)\n",
        "train_df['label'] = np.concatenate([np.zeros(len(train_normal)),np.ones(len(train_anomaly))])\n",
        "\n",
        "# 評価データのDataFrameの作成\n",
        "test_normal = read_data('slider','test','normal')\n",
        "test_anomaly = read_data('slider','test','anomaly')\n",
        "test = np.concatenate([test_normal,test_anomaly])\n",
        "test_df = pd.DataFrame()\n",
        "test_df['mean'] = np.sqrt(np.mean(test**2,axis=1))\n",
        "test_df['zc'] = np.sum(librosa.zero_crossings(test),axis=1)\n",
        "test_df['label'] = np.concatenate([np.zeros(len(test_normal)),np.ones(len(test_anomaly))])\n",
        "\n",
        "train_df[train_df['label']==0]['mean'].plot.hist(alpha=0.5, label='正常音')\n",
        "train_df[train_df['label']==1]['mean'].plot.hist(alpha=0.5, label='異常音(学習用)')\n",
        "test_df[test_df['label']==1]['mean'].plot.hist(alpha=0.5, label='異常音(評価用)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObsRbCLaY9FC"
      },
      "source": [
        "## 2.教師なし学習による異常検知"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-C82a8F4REz"
      },
      "source": [
        "### 2-1.教師なし学習による異常検知①"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo393iD44gWs"
      },
      "source": [
        "**正常と異常パターンを学習させていた教師あり学習から発想を変えて、正常パターンのみを学習させ、正常パターンと異なるものは異常と予測するモデルを作成**\n",
        "\n",
        "```\n",
        "1.   未知の異常にも対応できる\n",
        "2.   大量の異常データがなくても良い\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGsLWC7a41hO"
      },
      "source": [
        "### 2-2.教師なし学習による異常検知②"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu1CogkA46-K"
      },
      "source": [
        "### 2-3.One Class SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "basLo2XS48hx"
      },
      "source": [
        "**One Class SVM**\n",
        "\n",
        "```\n",
        "*   教師あり分類モデルであるSVMを、教師なしの1クラス分類に応用したモデル\n",
        "*   SVMなので標準化が必要\n",
        "*   識別境界を基準に正常か異常かを2値で返す\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzbQZage5aTT"
      },
      "source": [
        "### 2-4.標準化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrrMHRbq5hYf"
      },
      "source": [
        "**sklearnの標準化ライブラリ**\n",
        "\n",
        "```\n",
        "from sklearn import preprocessing\n",
        "\n",
        "sc = preprocessing.StandardScaler()\n",
        "sc.fit(X)\n",
        "sc.transform(X)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYSavGn5x4B"
      },
      "source": [
        "# 学習データのDataFrameの作成\n",
        "train = read_data('slider','train','normal')\n",
        "train_df = pd.DataFrame()\n",
        "train_df['mean']= np.sqrt(np.mean(train**2,axis=1))\n",
        "train_df['zc'] = np.sum(librosa.zero_crossings(train),axis=1)\n",
        "train_df['label'] = 0\n",
        "\n",
        "# 評価データのDataFrameの作成\n",
        "test_normal = read_data('slider','test','normal')\n",
        "test_anomaly = read_data('slider','test','anomaly')\n",
        "test = np.concatenate([test_normal,test_anomaly])\n",
        "test_df = pd.DataFrame()\n",
        "test_df['mean'] = np.sqrt(np.mean(test**2,axis=1))\n",
        "test_df['zc'] = np.sum(librosa.zero_crossings(test),axis=1)\n",
        "test_df['label'] = np.concatenate([np.zeros(len(test_normal)),np.ones(len(test_anomaly))])\n",
        "\n",
        "train_X, train_y = train_df[['mean','zc']], train_df['label']\n",
        "test_X, test_y = test_df[['mean','zc']], test_df['label']\n",
        "\n",
        "# 標準化\n",
        "from sklearn import preprocessing\n",
        "sc = preprocessing.StandardScaler()\n",
        "sc.fit(train_X)\n",
        "train_X = sc.transform(train_X)\n",
        "test_X = sc.transform(test_X)\n",
        "print(train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBqbmAfh57Dt"
      },
      "source": [
        "### 2-5.One Class SVMの作成・予測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dud9QER56EyO"
      },
      "source": [
        "**One Class SVMの学習と予測**\n",
        "\n",
        "```\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "model = OneClassSVM()\n",
        "model.fit(X)\n",
        "model.predict(X)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su0lfANo6QxN"
      },
      "source": [
        "train_X, train_y = train_df[['mean','zc']], train_df['label']\n",
        "test_X, test_y = test_df[['mean','zc']], test_df['label']\n",
        "\n",
        "# 標準化\n",
        "sc = preprocessing.StandardScaler()\n",
        "sc.fit(train_X)\n",
        "train_X = sc.transform(train_X)\n",
        "test_X = sc.transform(test_X)\n",
        "\n",
        "# モデルの作成・学習・予測\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "model = OneClassSVM()\n",
        "model.fit(train_X)\n",
        "pred = model.predict(test_X)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MVVD3Az6XT7"
      },
      "source": [
        "### 2-6.One Class SVMの精度評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HvpLKqC6eTN"
      },
      "source": [
        "**評価データの形式(0が正常、1が異常)に修正**\n",
        "\n",
        "```\n",
        "np.where(条件式, 真の場合の値, 偽の場合の値)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx5mx2Xs7bJH"
      },
      "source": [
        "train_X, train_y = train_df[['mean','zc']], train_df['label']\n",
        "test_X, test_y = test_df[['mean','zc']], test_df['label']\n",
        "\n",
        "# 標準化\n",
        "sc = preprocessing.StandardScaler()\n",
        "sc.fit(train_X)\n",
        "train_X = sc.transform(train_X)\n",
        "test_X = sc.transform(test_X)\n",
        "\n",
        "# モデルの作成・学習・予測\n",
        "model = OneClassSVM()\n",
        "model.fit(train_X)\n",
        "pred = model.predict(test_X)\n",
        "pred = np.where(pred==-1, 1, 0)\n",
        "print(confusion_matrix(test_y,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeuZJFAVWvsK"
      },
      "source": [
        "# [3] ポンプ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtY9vvYwZDqS"
      },
      "source": [
        "## 1.音声特徴量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVgMPu3e7fbu"
      },
      "source": [
        "### 1-1.教師あり学習による異常検知"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xImHEQUq7nZG"
      },
      "source": [
        "# train_df,test_dfにはポンプデータが代入されています。\n",
        "train_X, train_y = train_df[['mean','zc']], train_df['label']\n",
        "test_X, test_y = test_df[['mean','zc']], test_df['label']\n",
        "\n",
        "# 標準化\n",
        "sc = preprocessing.StandardScaler()\n",
        "sc.fit(train_X)\n",
        "train_X = sc.transform(train_X)\n",
        "test_X = sc.transform(test_X)\n",
        "\n",
        "# モデルの作成・学習・予測\n",
        "model = OneClassSVM(nu=0.01)\n",
        "model.fit(train_X)\n",
        "pred = model.predict(test_X)\n",
        "pred = np.where(pred==-1, 1, 0)\n",
        "print(confusion_matrix(test_y,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZDn4u468Y_R"
      },
      "source": [
        "### 1-2.パワースペクトル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9gA4mvk8fg_"
      },
      "source": [
        "**音声の特徴量としてよく使われるもの**\n",
        "\n",
        "```\n",
        "1.   パワースペクトル\n",
        "2.   スペクトログラム\n",
        "3.   メルスペクトログラム\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Qdn22e7feV"
      },
      "source": [
        "**パワースペクトルとは**\n",
        "\n",
        "```\n",
        "音声波形は通常複数のsin波で構成されています。即ち、音声波形の特徴=各sin波の特徴、と言い換えることができます。構成しているsin波に分解し、各sin波の周波数と振幅を記載したものをパワースペクトルと言います。\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSPhK6pt8-2v"
      },
      "source": [
        "### 1-3.パワースペクトルの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MZj3rjr9PMQ"
      },
      "source": [
        "def create_power_spectral(data):\n",
        "    N = data.shape[1]\n",
        "    dt = 10/N\n",
        "    F = np.abs(np.fft.fft(data)/(N/2))\n",
        "    fq = np.linspace(0,1/dt,N)\n",
        "    return F[:,:int(N/2)+1], fq[:int(N/2)+1]\n",
        "\n",
        "F, freq = create_power_spectral(train)\n",
        "plt.plot(freq,F[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykiWJ4H19b7K"
      },
      "source": [
        "### 1-4.スペクトログラム"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBdyv9Si9i0F"
      },
      "source": [
        "**スペクトログラムとは**\n",
        "\n",
        "```\n",
        "パワースペクトルには時間軸の情報が失われるという欠点がありました、そこでパワースペクトルに時間情報も持たせるために、一定時間ごとにパワースペクトルをとったものをスペクトログラムと言います。\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCWU56k69xO-"
      },
      "source": [
        "### 1-5.メルスペクトログラム"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dm1x1Zb95_H"
      },
      "source": [
        "**メル尺度とメルスペクトグラム**\n",
        "\n",
        "```\n",
        "周波数の間隔を人間が聞く感覚に近いように、低いところは細かく、高いところは粗く変換したものをメル尺度といいます。スペクトログラムの周波数をメル尺度化したものを、メルスペクトログラムといいます。\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZHINBg8-H1U"
      },
      "source": [
        "### 1-6.メルスペクトログラムの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yWgoAHI-NQP"
      },
      "source": [
        "**メルスペクトログラムを作成するための関数**\n",
        "\n",
        "```\n",
        "librosa.feature.melspectrogram(X)\n",
        "```\n",
        "**可視化するための関数**\n",
        "\n",
        "```\n",
        "librosa.diaplay.spechshow(X, x_axis='time', y_axis='mel')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smFmXeSu-5FF"
      },
      "source": [
        "# メルスペクトログラムの作成\n",
        "melspec = librosa.feature.melspectrogram(train[0])\n",
        "# 可視化\n",
        "librosa.display.specshow(melspec, x_axis='time', y_axis='mel')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-RziDb0_C6Y"
      },
      "source": [
        "### 1-7.デシベル変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bds96HST_HpN"
      },
      "source": [
        "**デジベルとは**\n",
        "\n",
        "```\n",
        "人間が感じる感覚に音量を変換したものをデシベル(dB)といいます。\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwrt6E-H_ShM"
      },
      "source": [
        "# メルスペクトログラムの作成\n",
        "melspec = librosa.feature.melspectrogram(train[0])\n",
        "# デシベル変換\n",
        "melspec_db = librosa.amplitude_to_db(melspec)\n",
        "# 可視化\n",
        "librosa.display.specshow(melspec_db, x_axis='time', y_axis='mel')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rHxSVNa_Zd_"
      },
      "source": [
        "### 1-8.One Class SVMの精度評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BnHfpZQ_qH7"
      },
      "source": [
        "**メルスペクトログラムは2次元配列になっているため、flatten()で1次元にする**\n",
        "\n",
        "```\n",
        "# 学習データのDataFrameの作成\n",
        "train = read_data('pump','train','normal')\n",
        "melspec_dbs = []\n",
        "for i in range(len(train)):\n",
        "    # メルスペクトログラムの作成\n",
        "    melspec = librosa.feature.melspectrogram(train[i])\n",
        "    # dB化\n",
        "    melspec_db = librosa.amplitude_to_db(melspec).flatten()\n",
        "    melspec_dbs.append(melspec_db.astype(np.float16))\n",
        "train_df = pd.DataFrame(melspec_dbs)\n",
        "\n",
        "# 評価データのDataFrameの作成\n",
        "test_normal = read_data('pump','test','normal')\n",
        "test_anomaly = read_data('pump','test','anomaly')\n",
        "test = np.concatenate([test_normal,test_anomaly])\n",
        "melspec_dbs = []\n",
        "for i in range(len(test)):\n",
        "    # メルスペクトログラムの作成\n",
        "    melspec = librosa.feature.melspectrogram(test[i])\n",
        "    # dB化\n",
        "    melspec_db = librosa.amplitude_to_db(melspec).flatten()\n",
        "    melspec_dbs.append(melspec_db.astype(np.float16))\n",
        "test_df = pd.DataFrame(melspec_dbs)\n",
        "test_df['label'] = np.concatenate([np.zeros(len(test_normal)),np.ones(len(test_anomaly))])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SJLqU2fAEwH"
      },
      "source": [
        "train_X = train_df\n",
        "test_X, test_y = test_df.drop(columns=['label']), test_df['label']\n",
        "\n",
        "# # 標準化\n",
        "sc = preprocessing.StandardScaler()\n",
        "sc.fit(train_X)\n",
        "train_X = sc.transform(train_X)\n",
        "test_X = sc.transform(test_X)\n",
        "\n",
        "# モデルの作成・学習・予測\n",
        "model = OneClassSVM()\n",
        "model.fit(train_X)\n",
        "pred = model.predict(test_X)\n",
        "pred = np.where(pred==-1, 1, 0)\n",
        "print(confusion_matrix(test_y,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POlOgC5FWvuu"
      },
      "source": [
        "# [4] ファン"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e90EDNcMZHIo"
      },
      "source": [
        "## 1.Autoencoderによる異常検知"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxo-erNis4xb"
      },
      "source": [
        "### 1-1.Autoencoderによる異常検知"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2Af6aMtH6g"
      },
      "source": [
        "```\n",
        "正常音と異常音で大きく異なる音の特徴が音量なら平均振幅を、音色ならばスペクトログラムやMFCC(メル周波数ケプストラム係数)を、ノイズならばゼロクロス数を特徴量に使用する必要があり、特徴量を間違えると精度の良いモデルは作成できない。\n",
        "```\n",
        "**Autoencoder**\n",
        "\n",
        "```\n",
        "*   DeepLearningの一種であるため、特徴量を手動で決める必要がない\n",
        "*   入力データを圧縮し、再度入力データを復元するネットワーク\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pOvvmgUuA9O"
      },
      "source": [
        "### 1-2.Autoencoderの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ch8FApGuHkX"
      },
      "source": [
        "import keras.models\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Activation\n",
        "from keras.models import Sequential\n",
        "\n",
        "inputDim = 40064\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64,input_shape=(inputDim,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(8))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(inputDim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSk3Dw_0uNmr"
      },
      "source": [
        "### 1-3.モデルの学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kHa1mASuTKW"
      },
      "source": [
        "**最適化アルゴリズムにはadamを、損失関数には平均二乗誤差を使用**\n",
        "\n",
        "```\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "```\n",
        "**Autoencoderの場合は入力データが復元できるように学習させるので、x,yともに同じデータを与える**\n",
        "\n",
        "```\n",
        "history = model.fit(x=学習データ, y=学習データ, epochs=10, batch_size=50, validation_split=0.1)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh5nWypTuwZB"
      },
      "source": [
        "### 1-4.異常度の算出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-ag5MJsu55v"
      },
      "source": [
        "train_X = train_df\n",
        "test_X, test_y = test_df.drop(columns=['label']), test_df['label']\n",
        "\n",
        "model = keras.models.load_model('model.h5', compile=False)\n",
        "train_pred = model.predict(train_X)\n",
        "# 異常度の算出\n",
        "train_score = np.mean(np.square(train_X- train_pred), axis=1)\n",
        "\n",
        "# 学習データの異常度のヒストグラム\n",
        "train_score.plot.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYmfwf95vEYj"
      },
      "source": [
        "### 1-5.閾値の決定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v31pQjHrvNew"
      },
      "source": [
        "train_X = train_df\n",
        "test_X, test_y = test_df.drop(columns=['label']), test_df['label']\n",
        "\n",
        "model = keras.models.load_model('model.h5', compile=False)\n",
        "train_pred = model.predict(train_X)\n",
        "train_score = np.mean(np.square(train_X- train_pred), axis=1)\n",
        "\n",
        "test_pred = model.predict(test_X)\n",
        "test_score = np.mean(np.square(test_X - test_pred), axis=1)\n",
        "\n",
        "# 閾値の設定\n",
        "threshold = train_score.quantile(0.8)\n",
        "\n",
        "# 異常度が閾値より大きければ1、小さければ0に\n",
        "pred = np.where(test_score > threshold, 1, 0)\n",
        "print(confusion_matrix(test_y,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEUn_CJzs40r"
      },
      "source": [
        ""
      ]
    }
  ]
}